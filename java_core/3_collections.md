Чтобы подготовиться к собеседованию на позицию Senior Java Developer, важно не только знать базовые понятия о коллекциях Java, но и глубоко понимать их работу, оптимальное использование и производительность. Ниже я разбиваю каждую из тем на подтемы, которые стоит изучить для полноценного понимания коллекций в Java:

### 1. **Интерфейсы `Collection` и `Map`**
- **Общая концепция коллекций**: что такое `Collection`, какие интерфейсы она расширяет, и какова роль `Map`.
- **Типы коллекций**: отличия между `Collection` (наборы элементов) и `Map` (наборы ключ-значение).
- **Особенности методов интерфейсов**:
    - `Collection`: методы `add()`, `remove()`, `contains()`, `size()`, `isEmpty()`, `iterator()`.
    - `Map`: методы `put()`, `get()`, `remove()`, `keySet()`, `values()`, `entrySet()`.
- **Различия между `Collection` и `Map` в использовании и подходе к работе с данными.**

### 2. **List (ArrayList, LinkedList)**
- **Основные интерфейсы и классы**:
    - Интерфейс `List`: возможности работы с элементами по индексу, порядок элементов, доступ к элементам.
    - Реализация `ArrayList`:
        - Особенности внутренней работы (динамический массив, увеличение размера).
        - Время выполнения операций: `add()`, `get()`, `remove()`.
        - Производительность в разных сценариях.
    - Реализация `LinkedList`:
        - Особенности (двусвязный список, элементы не смежные в памяти).
        - Время выполнения операций, преимущества и недостатки по сравнению с `ArrayList`.
- **Применимость `ArrayList` и `LinkedList` в различных сценариях.**
- **Сравнение производительности и оптимальные случаи использования.**

### 3. **Set (HashSet, TreeSet, LinkedHashSet)**
- **Основной интерфейс `Set`**: отличие от `List`, уникальность элементов.
- **Реализация `HashSet`**:
    - Хеширование, внутренняя работа, особенности `hashCode()` и `equals()`.
    - Проблемы коллизий и их решения.
- **Реализация `TreeSet`**:
    - Работа через `NavigableSet`, особенности сортировки, основы внутренней структуры (красно-черное дерево).
    - Время выполнения операций (`add()`, `remove()`, `contains()`).
- **Реализация `LinkedHashSet`**:
    - Сочетание преимуществ хеширования с поддержкой порядка добавления элементов.
    - Когда применять по сравнению с `HashSet` и `TreeSet`.
- **Сравнение производительности и выбор нужной реализации в зависимости от задачи.**

### 4. **Queue (PriorityQueue, Deque, ArrayDeque)**
- **Интерфейс `Queue`**: основные методы (`offer()`, `poll()`, `peek()`), контракт FIFO.
- **Реализация `PriorityQueue`**:
    - Особенности очереди с приоритетами, работа с элементами через естественный порядок или компаратор.
    - Внутренняя структура (куча) и алгоритмы добавления/удаления.
- **Интерфейс `Deque`**: возможности работы как с очередью (FIFO), так и с деком (LIFO).
- **Реализация `ArrayDeque`**:
    - Преимущества перед `LinkedList` для работы с деком.
    - Время выполнения операций добавления/удаления с разных концов.
- **Сценарии использования `PriorityQueue`, `Deque` и `ArrayDeque` в зависимости от требований задачи.**

### 5. **Map (HashMap, TreeMap, LinkedHashMap, Hashtable)**
- **Интерфейс `Map`**: основные методы и их контракт (`put()`, `get()`, `remove()`, `keySet()`, `entrySet()`).
- **Реализация `HashMap`**:
    - Хеширование ключей, разрешение коллизий (начиная с Java 8 — красно-черные деревья).
    - Время выполнения операций и внутренние оптимизации.
    - Проблемы с потокобезопасностью.
- **Реализация `TreeMap`**:
    - Дерево на основе ключей, контракт для сортировки ключей, красно-черное дерево.
    - Время выполнения операций.
- **Реализация `LinkedHashMap`**:
    - Поддержка порядка вставки или доступа, отличие от `HashMap`.
    - Использование в кэшах (например, LRU Cache).
- **Реализация `Hashtable`**:
    - Историческая реализация, потокобезопасность и проблемы конкурентности.
    - Почему чаще стоит использовать `ConcurrentHashMap`.
- **Сравнение производительности и сценарии выбора правильной реализации в зависимости от требований к сортировке, скорости и потокобезопасности.**

### 6. **Основные методы и операции с коллекциями**
- **Методы `Collection` API**: `addAll()`, `removeAll()`, `retainAll()`, `clear()`, `containsAll()`.
- **Работа с подколлекциями**: создание неизменяемых коллекций, использование `subList()`, `headSet()`, `tailSet()`.
- **Методы работы с `Map`**: работа с `keySet()`, `values()`, `entrySet()`, проход по коллекции `Map.Entry`.
- **Оптимизация работы с коллекциями**: как избежать лишних операций, примеры оптимального использования методов коллекций.

### 7. **Итераторы, `ListIterator`**
- **Интерфейс `Iterator`**: методы `hasNext()`, `next()`, `remove()`.
- **`ListIterator`**:
    - Дополнительные возможности (`hasPrevious()`, `previous()`, `set()`).
    - Использование в двухсторонних списках (например, `LinkedList`).
- **Безопасность итераций**:
    - Проблема ConcurrentModificationException.
    - Использование модифицируемых и немодифицируемых коллекций.
    - Потокобезопасные итераторы (например, через `CopyOnWriteArrayList`).

### 8. **Comparator и Comparable**
- **Интерфейс `Comparable`**:
    - Контракт метода `compareTo()`.
    - Примеры использования при сортировке через `Collections.sort()` и в структурах данных (например, `TreeSet`, `TreeMap`).
- **Интерфейс `Comparator`**:
    - Внешняя сортировка, возможности компараторов (например, создание цепочек через `Comparator.thenComparing()`).
- **Отличие `Comparable` и `Comparator`, примеры сложных сортировок.**
- **Лямбда-выражения и функциональные интерфейсы для создания компараторов (начиная с Java 8).**
- **Примеры сортировок коллекций с использованием этих интерфейсов, в том числе сложные сортировки по нескольким критериям.**


Давайте подробно рассмотрим интерфейсы `Collection` и `Map` в Java, их концепцию, отличия и методы.

### Общая концепция коллекций

#### Интерфейс `Collection`

`Collection` — это корневой интерфейс в иерархии коллекций Java. Он представляет собой набор элементов и определяет общие операции для всех коллекций, таких как добавление, удаление и проверка наличия элементов. Все другие интерфейсы коллекций (например, `List`, `Set`, `Queue`) расширяют `Collection`, что позволяет использовать единый набор методов для работы с любыми коллекциями.

Основные расширения `Collection`:
- `List`: Упорядоченные коллекции, позволяющие доступ к элементам по индексу.
- `Set`: Наборы уникальных элементов без дубликатов.
- `Queue`: Коллекции для работы с элементами по принципу очереди (FIFO).
- `Deque`: Двунаправленные очереди, которые позволяют добавлять и удалять элементы с обеих сторон.

#### Интерфейс `Map`

`Map` представляет собой коллекцию, хранящую элементы в виде пар "ключ-значение". Ключи в `Map` уникальны, а значения могут повторяться. `Map` не является расширением `Collection`, но имеет похожие методы для работы с данными, и часто его рассматривают вместе с коллекциями, потому что он также служит для хранения и управления данными.

Основные реализации `Map`:
- `HashMap`: Неупорядоченная реализация, которая использует хеш-таблицу.
- `TreeMap`: Реализация, которая хранит элементы в отсортированном порядке на основе естественного порядка ключей или предоставленного компаратора.
- `LinkedHashMap`: Реализация, которая сохраняет порядок добавления элементов.
- `Hashtable`: Потокобезопасная реализация, которая является устаревшей по сравнению с `ConcurrentHashMap`.

### Типы коллекций и их отличия

#### `Collection`

Коллекции, которые расширяют `Collection`, включают:
- **`List`**: Например, `ArrayList`, `LinkedList`. Сохраняют порядок элементов и позволяют доступ по индексу.
- **`Set`**: Например, `HashSet`, `TreeSet`, `LinkedHashSet`. Хранят только уникальные элементы и не гарантируют порядок (в случае `HashSet`) или упорядочивают элементы по какому-то критерию (в случае `TreeSet`).
- **`Queue`**: Например, `PriorityQueue`, `ArrayDeque`. Предназначены для работы с элементами в порядке их добавления и/или приоритетов.
- **`Deque`**: Например, `ArrayDeque`. Поддерживает работу с элементами с обеих сторон.

#### `Map`

`Map` хранит данные в виде пар ключ-значение:
- **`HashMap`**: Хранит элементы в хеш-таблице, обеспечивая быструю вставку и поиск.
- **`TreeMap`**: Сортирует элементы на основе ключей, предоставленных компаратором или естественным порядком.
- **`LinkedHashMap`**: Хранит элементы в порядке их вставки.
- **`Hashtable`**: Хранит элементы в хеш-таблице и является потокобезопасной реализацией.

### Особенности методов интерфейсов

#### Методы интерфейса `Collection`

- **`add(E e)`**: Добавляет элемент в коллекцию. Возвращает `true`, если элемент был добавлен.
- **`remove(Object o)`**: Удаляет элемент из коллекции. Возвращает `true`, если элемент был успешно удален.
- **`contains(Object o)`**: Проверяет наличие элемента в коллекции. Возвращает `true`, если элемент присутствует.
- **`size()`**: Возвращает количество элементов в коллекции.
- **`isEmpty()`**: Проверяет, пуста ли коллекция. Возвращает `true`, если коллекция не содержит элементов.
- **`iterator()`**: Возвращает итератор для перебора элементов коллекции. Итератор позволяет безопасно обходить элементы и удалять их, если это поддерживается коллекцией.

#### Методы интерфейса `Map`

- **`put(K key, V value)`**: Добавляет пару ключ-значение в `Map`. Если ключ уже существует, обновляет значение и возвращает предыдущее значение.
- **`get(Object key)`**: Возвращает значение по указанному ключу. Возвращает `null`, если ключ не найден.
- **`remove(Object key)`**: Удаляет пару ключ-значение по указанному ключу. Возвращает удаленное значение или `null`, если ключ не найден.
- **`keySet()`**: Возвращает набор всех ключей в `Map`.
- **`values()`**: Возвращает коллекцию всех значений в `Map`.
- **`entrySet()`**: Возвращает набор пар ключ-значение (`Map.Entry`), который позволяет перебирать элементы `Map` более эффективно.

### Различия между `Collection` и `Map`

- **Структура хранения данных**:
  - `Collection` хранит только элементы (например, `List`, `Set`).
  - `Map` хранит данные в виде пар ключ-значение.

- **Доступ к элементам**:
  - В `Collection` доступ к элементам осуществляется по их порядку или уникальности.
  - В `Map` доступ к значениям осуществляется через ключи.

- **Уникальность**:
  - В `Set` (расширяет `Collection`) элементы уникальны, в `List` элементы могут повторяться.
  - В `Map` ключи уникальны, а значения могут повторяться.

- **Применение**:
  - `Collection` используется для хранения групп объектов, где порядок и уникальность элементов могут быть важны.
  - `Map` используется для хранения данных в виде пар, где требуется быстрый доступ по ключу и возможность обновления значений.

### Заключение

Понимание интерфейсов `Collection` и `Map` и их методов является основой для эффективного управления данными в Java. Знание их особенностей поможет в выборе подходящей структуры данных для различных задач, оптимизации производительности и написании чистого и поддерживаемого кода.

Для позиции Senior Java Developer важно иметь глубокое понимание различных реализаций коллекций в Java, таких как `ArrayList` и `LinkedList`, а также их особенностей и производительности. Давайте рассмотрим это подробно.

# Интерфейс List

## ArrayList

`ArrayList` — это один из самых популярных классов в Java, который реализует динамический массив. Под капотом он использует массив для хранения элементов, что накладывает определенные особенности на его работу и время выполнения операций.

### **Основы работы `ArrayList`**

1. **Внутреннее представление:**
  * Внутренне `ArrayList` использует массив типа `Object[]` для хранения своих элементов.
  * При создании `ArrayList` можно задать начальную емкость (capacity), т.е. размер внутреннего массива. Если начальная емкость не указана, то по умолчанию она равна 10\.
2. **Резервирование места (Capacity и Size):**
  * `Capacity` — это размер внутреннего массива.
  * `Size` — это текущее количество элементов, находящихся в `ArrayList`.
3. **Ресайз массива:**
  * Если размер (Size) становится больше емкости (Capacity), `ArrayList` автоматически увеличивает свой размер. Это делается с помощью создания нового массива большего размера и копирования всех элементов из старого массива в новый.
  * По умолчанию новая емкость будет примерно в 1.5 раза больше текущей (формула увеличения `newCapacity = oldCapacity + (oldCapacity >> 1)`).

### **Время выполнения операций**

* **Добавление (insert) элемента в конец:**
  * `add(E e)`: Операция добавления в конец массива имеет **амортизированное время выполнения O(1)**. Если не нужно изменять размер массива, то элемент просто добавляется в конец.
  * Если массив заполнен, то требуется создание нового массива, копирование всех элементов в новый массив и добавление нового элемента. Этот процесс имеет время O(n), но такое случается редко, поэтому амортизированное время — O(1).
* **Добавление элемента в середину или начало:**
  * `add(int index, E element)`: Чтобы вставить элемент в середину массива, нужно сдвинуть все элементы справа от вставляемого индекса на одну позицию вправо. Это операция имеет время выполнения **O(n)** в худшем случае.
* **Удаление (remove) элемента:**
  * `remove(int index)`: При удалении элемента по индексу, все элементы справа от удаленного элемента нужно сдвинуть на одну позицию влево, чтобы заполнить "пустое" место. Это операция занимает **O(n)** времени.
  * `remove(Object o)`: Вначале требуется найти элемент (O(n)), а затем удалить его (O(n)), что в сумме дает **O(n)**.
* **Получение (get) элемента:**
  * `get(int index)`: Получение элемента по индексу происходит за **O(1)**, так как это прямая операция доступа к элементу массива.
* **Изменение (set) элемента:**
  * `set(int index, E element)`: Замена элемента по индексу также занимает **O(1)**, поскольку это прямая операция доступа.

### **Дополнительные особенности**

1. **Итерация:**
  * `ArrayList` поддерживает быструю итерацию по элементам благодаря внутреннему использованию массива. Временная сложность итерации через `for` или `Iterator` — O(n).
2. **Проблемы с эффективностью:**
  * Так как `ArrayList` использует массив, вставка и удаление элементов, особенно в начале или в середине списка, могут быть неэффективными (O(n)), поскольку требуют сдвига большого количества элементов.
  * Если емкость увеличивается до очень большого размера, может возникнуть проблема памяти.
3. **Потокобезопасность:**
  * `ArrayList` не является потокобезопасным. Для многопоточных сред лучше использовать `Vector` или `Collections.synchronizedList(new ArrayList<>())`.

### **Заключение**

`ArrayList` — это мощный и гибкий инструмент для работы с динамическими массивами в Java, который обеспечивает быстрый доступ по индексу и добавление в конец, но может страдать от неэффективности при частых вставках или удалениях в середине.

## LinkedList

`LinkedList` — это другая популярная коллекция в Java, которая реализует двусвязный список. В отличие от `ArrayList`, который использует массив для хранения элементов, `LinkedList` хранит элементы в виде узлов (Node), связанных друг с другом ссылками.

### **Основы работы `LinkedList`**

1. **Внутреннее представление:**
  * `LinkedList` состоит из узлов (Node), где каждый узел содержит:
    * Значение (data) элемента.
    * Ссылку на следующий узел (`next`).
    * Ссылку на предыдущий узел (`prev`).
  * `LinkedList` хранит две ссылки: `first` (голова списка) и `last` (хвост списка).
2. **Структура узла (Node):**

private static class Node\<E\> {  
E item;         // Значение узла  
Node\<E\> next;   // Ссылка на следующий узел  
Node\<E\> prev;   // Ссылка на предыдущий узел

    Node(Node\<E\> prev, E element, Node\<E\> next) {  
        this.item \= element;  
        this.next \= next;  
        this.prev \= prev;  
    }  
}

### **Время выполнения операций**

* **Добавление (insert) элемента в начало или конец:**
  * `addFirst(E e)` и `addLast(E e)` (или просто `add(E e)`): Эти методы добавляют элемент в начало или конец списка соответственно. Это **O(1)** операция, так как нужно только обновить ссылки на первый или последний узел.
  * `add(int index, E element)`: Вставка по индексу требует сначала пройти до этого индекса, что занимает **O(n/2)** времени в среднем (если индекс ближе к началу, то идем с начала, если к концу — с конца), а затем вставка занимает **O(1)**.
* **Удаление (remove) элемента:**
  * `removeFirst()` и `removeLast()`: Удаление первого или последнего элемента — это **O(1)** операция, так как нужно просто изменить ссылки на голову или хвост.
  * `remove(int index)`: Удаление по индексу требует поиска этого индекса (в среднем **O(n/2)**) и удаления узла (**O(1)**).
  * `remove(Object o)`: Требуется пройтись по списку, чтобы найти элемент (**O(n)**), а затем выполнить удаление узла (**O(1)**), что в сумме даёт **O(n)**.
* **Получение (get) элемента:**
  * `get(int index)`: Получение элемента по индексу требует прохождения списка до нужного индекса. Средняя временная сложность составляет **O(n/2)**, что даёт в общем случае **O(n)**.
* **Изменение (set) элемента:**
  * `set(int index, E element)`: Для изменения элемента требуется пройти по списку до нужного индекса (O(n)), а затем заменить значение узла на новое значение, что занимает **O(1)**. Общая временная сложность — **O(n)**.

### **Дополнительные особенности**

1. **Итерация:**
  * Итерация через `LinkedList` с использованием `for` или `Iterator` имеет сложность **O(n)**, так как каждый элемент требует доступа по ссылке.
2. **Отличия от `ArrayList`:**
  * **Динамическое изменение размера:** `LinkedList` может динамически изменять размер, но в отличие от `ArrayList`, `LinkedList` не нужно увеличивать или уменьшать массив. Вместо этого добавление и удаление элементов требует работы со ссылками узлов.
  * **Память:** `LinkedList` требует больше памяти, чем `ArrayList`, поскольку каждый элемент хранит ссылки на предыдущий и следующий элементы.
  * **Доступ по индексу:** `ArrayList` предоставляет быстрый доступ по индексу (`O(1)`), а у `LinkedList` доступ по индексу занимает `O(n)`.
3. **Потокобезопасность:**
  * Как и `ArrayList`, `LinkedList` не является потокобезопасным. Для многопоточной среды лучше использовать синхронизированные версии или `CopyOnWriteArrayList`.

### **Заключение**

`LinkedList` — это хороший выбор для приложений, где требуется часто добавлять или удалять элементы в начале или в середине коллекции, так как эти операции имеют более низкую временную сложность по сравнению с `ArrayList`. Однако, для задач, где часто требуется доступ по индексу или интенсивные операции чтения, `ArrayList` будет предпочтительнее.

## Vector

`Vector` — это класс в Java, который представляет собой динамический массив, очень похожий на `ArrayList`. Однако `Vector` является *устаревшим* и менее популярным, поскольку он синхронизирован по умолчанию, что делает его менее производительным по сравнению с `ArrayList` в однопоточных средах. Несмотря на это, `Vector` все еще используется в некоторых проектах и стоит понимать, как он работает под капотом.

### **Основы работы `Vector`**

1. **Внутреннее представление:**
  * `Vector` использует массив типа `Object[]` для хранения своих элементов.
  * Как и `ArrayList`, `Vector` может динамически изменять размер массива при необходимости.
2. **Резервирование места (Capacity и Size):**
  * `Capacity` — это размер внутреннего массива, который увеличивается по мере необходимости.
  * `Size` — это текущее количество элементов в `Vector`.
  * У `Vector` можно задать начальную емкость и коэффициент увеличения (capacity increment). Если не задано, по умолчанию емкость увеличивается вдвое при каждом переполнении массива.
3. **Ресайз массива:**
  * Если массив заполняется, `Vector` создает новый массив большего размера (обычно в два раза больше текущего) и копирует все элементы из старого массива в новый.

### **Время выполнения операций**

* **Добавление (insert) элемента в конец:**
  * `add(E e)` или `addElement(E e)`: Добавление элемента в конец имеет **амортизированное время выполнения O(1)**. Если массив не заполнен, элемент просто добавляется в конец. Если массив заполнен, то происходит его увеличение и копирование элементов, что занимает **O(n)**, но это происходит нечасто.
* **Добавление элемента в середину или начало:**
  * `add(int index, E element)`: Чтобы вставить элемент в середину или начало, все элементы справа от вставляемого индекса нужно сдвинуть на одну позицию вправо. Это занимает **O(n)** в худшем случае.
* **Удаление (remove) элемента:**
  * `remove(int index)` или `removeElementAt(int index)`: Удаление элемента требует сдвига всех элементов справа от удаленного индекса на одну позицию влево. Это операция занимает **O(n)** времени.
  * `remove(Object o)` или `removeElement(Object obj)`: Вначале требуется найти элемент (O(n)), а затем удалить его (O(n)), что в сумме дает **O(n)**.
* **Получение (get) элемента:**
  * `get(int index)` или `elementAt(int index)`: Получение элемента по индексу является **O(1)** операцией, так как это прямая операция доступа к элементу массива.
* **Изменение (set) элемента:**
  * `set(int index, E element)` или `setElementAt(E obj, int index)`: Замена элемента по индексу также занимает **O(1)**.

### **Дополнительные особенности**

1. **Потокобезопасность:**
  * `Vector` синхронизирован по умолчанию, что означает, что все его методы являются потокобезопасными. Это достигается с помощью синхронизации всех публичных методов. Например, `add` метод выглядит следующим образом:

public synchronized boolean add(E e) {  
ensureCapacityHelper(elementCount \+ 1);  
elementData\[elementCount++\] \= e;  
return true;  
}

* Из-за этого операции `Vector` более медленные, чем у `ArrayList`, в однопоточной среде. В многопоточной среде, однако, синхронизированный доступ делает `Vector` безопасным.

**Итерация:**

* Итерация через `Vector` может быть менее эффективной, чем `ArrayList`, из\-за синхронизации методов. Итерация с помощью `for` или `Iterator` имеет сложность **O(n)**.

**Устаревание:**

* `Vector` считается устаревшим и не рекомендуется для использования в новых приложениях. Вместо него лучше использовать `ArrayList` вместе с `Collections.synchronizedList` для обеспечения потокобезопасности или `CopyOnWriteArrayList` для сценариев с минимальным изменением и высокой скоростью чтения.

**Емкость и увеличение:**

* По умолчанию `Vector` увеличивает емкость в два раза, когда она превышается. Однако, можно указать `capacityIncrement`, чтобы настроить увеличение емкости в фиксированном размере. Например:

Vector\<Integer\> vector \= new Vector\<\>(initialCapacity, capacityIncrement);

* Это делает `Vector` более гибким, но также может приводить к избыточному использованию памяти.

### **Заключение**

`Vector` — это синхронизированная версия динамического массива в Java. Он обеспечивает потокобезопасность, но при этом менее производителен, чем `ArrayList` в однопоточных средах. Время выполнения основных операций аналогично `ArrayList`, но из\-за синхронизации `Vector` часто проигрывает в скорости. В новых проектах `Vector` используется редко, и предпочтение отдается более современным и эффективным структурам данных, таким как `ArrayList` и `CopyOnWriteArrayList`.

## Stack

`Stack` в Java — это класс, который представляет собой структуру данных "стек" (LIFO — *Last In, First Out*), то есть элементы добавляются и удаляются только с одной стороны — вершины стека. `Stack` наследует `Vector`, что делает его синхронизированным по умолчанию. Из-за этого `Stack` также имеет схожие с `Vector` ограничения и особенности в производительности.

### **Основы работы `Stack`**

1. **Наследование от `Vector`:**
  * `Stack` расширяет класс `Vector`, поэтому его внутреннее представление основано на динамическом массиве `Object[]`, который используется для хранения элементов.
  * Поскольку `Stack` наследует методы и поля от `Vector`, он также обладает такими характеристиками, как начальная емкость, увеличение емкости, синхронизация и методы для управления элементами.
2. **Операции в `Stack`:**
  * Основные операции стека включают добавление элемента на вершину (`push`), удаление элемента с вершины (`pop`), просмотр верхнего элемента без удаления (`peek`), проверку, пуст ли стек (`empty`), и поиск элемента (`search`).

### **Время выполнения операций**

* **Добавление элемента (`push`):**
  * `push(E item)`: Эта операция добавляет элемент в конец внутреннего массива `Vector` (то есть на вершину стека). Время выполнения аналогично `add` в `Vector` и составляет **амортизированное O(1)**. Если массив не заполнен, элемент добавляется за O(1). Если же массив переполнен, требуется его увеличение, что занимает **O(n)**, но такое случается редко.
* **Удаление элемента (`pop`):**
  * `pop()`: Операция удаления верхнего элемента из стека, что эквивалентно удалению последнего элемента в массиве. Это **O(1)** операция, поскольку не требуется сдвигать элементы. Возвращает удаленный элемент. Если стек пуст, генерируется исключение `EmptyStackException`.
* **Просмотр верхнего элемента (`peek`):**
  * `peek()`: Эта операция возвращает верхний элемент стека без его удаления. Она выполняется за **O(1)**, поскольку просто обращается к последнему элементу внутреннего массива.
* **Проверка на пустоту (`empty`):**
  * `empty()`: Возвращает `true`, если стек пуст, и `false` в противном случае. Эта операция выполняется за **O(1)**.
* **Поиск элемента (`search`):**
  * `search(Object o)`: Эта операция возвращает 1-based позицию элемента в стеке, начиная с вершины. Если элемент не найден, возвращается `-1`. Поскольку необходимо пройти по всему внутреннему массиву, в худшем случае эта операция имеет сложность **O(n)**.

### **Дополнительные особенности**

1. **Синхронизация:**
  * Поскольку `Stack` наследует `Vector`, все его методы синхронизированы, что делает его потокобезопасным, но менее производительным в однопоточных средах по сравнению с `ArrayDeque` или другими нерекомендованными коллекциями.
2. **Использование памяти:**
  * `Stack` использует массив для хранения элементов, поэтому его использование памяти зависит от размера массива. При увеличении размера массива на основе его текущей емкости (обычно в два раза) может возникнуть избыточное использование памяти.
3. **Наследие и альтернативы:**
  * `Stack` считается устаревшим классом, и для новых проектов рекомендуется использовать `ArrayDeque` или `LinkedList` в качестве стека, так как они предлагают более высокую производительность, гибкость и меньшую сложность при использовании.
4. **Итерация:**
  * Итерация через `Stack` аналогична итерации через `Vector` и имеет временную сложность **O(n)**.

### **Примеры использования методов `Stack`**

Stack\<Integer\> stack \= new Stack\<\>();

// Добавление элементов  
stack.push(1);  
stack.push(2);  
stack.push(3);  // Стек: \[1, 2, 3\]

// Просмотр верхнего элемента  
int top \= stack.peek();  // Вернет 3

// Удаление элемента  
int popped \= stack.pop();  // Удаляет и возвращает 3

// Проверка на пустоту  
boolean isEmpty \= stack.empty();  // false

// Поиск элемента  
int position \= stack.search(1);  // Вернет 2, так как позиции отсчитываются с 1

### **Заключение**

`Stack` — это устаревшая, но все еще используемая структура данных в Java, которая основана на `Vector` и обеспечивает синхронизированный доступ к элементам. Основные операции, такие как `push`, `pop`, `peek`, выполняются за O(1), что делает `Stack` подходящим для множества задач, но из\-за синхронизации и устаревшего дизайна он часто уступает в производительности современным альтернативам, таким как `ArrayDeque`.

# Queue

## PriorityQueue \- очередь на основе приоритетов. Нельзя использовать NULL

`PriorityQueue` в Java — это структура данных, основанная на **очереди с приоритетами**. В отличие от стандартной очереди (FIFO — First In, First Out), в `PriorityQueue` элементы извлекаются в порядке приоритета, который определяется либо естественным порядком (для объектов, реализующих интерфейс `Comparable`), либо с помощью переданного компаратора (`Comparator`).

### **Основы работы `PriorityQueue`**

1. **Внутреннее представление:**
  * Под капотом `PriorityQueue` реализована на основе **двоичной кучи (binary heap)**, которая представлена в виде **динамического массива** `Object[]`. Это позволяет эффективно поддерживать структуру кучи.
  * Важные свойства кучи: минимальный элемент всегда находится на вершине (корне) кучи. Таким образом, операция удаления (`poll`) или извлечения (`peek`) минимального элемента выполняется быстро.
  * `PriorityQueue` не допускает `null` элементов.
2. **Инициализация:**
  * `PriorityQueue` имеет начальную емкость по умолчанию (11 элементов). Эта емкость увеличивается по мере необходимости.
  * Емкость очереди может быть задана при создании, и также может быть передан пользовательский `Comparator` для задания порядка сортировки элементов.
3. **Резервирование места (Capacity и Size):**
  * `Capacity` — это текущий размер внутреннего массива.
  * `Size` — это текущее количество элементов в `PriorityQueue`.
4. **Ресайз массива:**
  * Если очередь переполняется (то есть количество элементов становится больше текущей емкости), внутренний массив увеличивается в 1.5 раза (аналогично `ArrayList`).

### **Время выполнения операций**

* **Добавление элемента (`offer`/`add`):**
  * `offer(E e)` или `add(E e)`: Операция добавления элемента в `PriorityQueue` имеет сложность **O(log n)**, так как элемент добавляется в конец внутреннего массива, а затем выполняется операция **"просеивания вверх" (heapify-up)**, чтобы поддерживать свойства кучи.
* **Удаление минимального элемента (`poll`):**
  * `poll()`: Удаляет и возвращает минимальный элемент (корень кучи) в очереди. Эта операция выполняется за **O(log n)**, так как после удаления минимального элемента требуется замена корня последним элементом и выполнение **"просеивания вниз" (heapify-down)** для восстановления структуры кучи.
* **Просмотр минимального элемента (`peek`):**
  * `peek()`: Возвращает минимальный элемент в очереди без его удаления. Это **O(1)** операция, так как минимальный элемент всегда находится на вершине (корне) кучи.
* **Удаление конкретного элемента (`remove`):**
  * `remove(Object o)`: Эта операция требует сначала поиска элемента, что в худшем случае может занять **O(n)**, а затем удаления, что требует **O(log n)** для восстановления кучи. В сумме — **O(n)**.
* **Проверка на наличие элемента (`contains`):**
  * `contains(Object o)`: Эта операция требует линейного поиска по внутреннему массиву, поэтому выполняется за **O(n)**.

### **Дополнительные особенности**

1. **Реализация кучи:**
  * `PriorityQueue` реализует **минимальную двоичную кучу**, где каждый узел меньше (или равен) своим дочерним узлам.
  * Внутренний массив представляет собой **полное двоичное дерево**, что позволяет эффективно выполнять операции вставки и удаления.
2. **Итерация:**
  * `PriorityQueue` не предоставляет гарантий порядка при итерации, так как элементы хранятся в виде кучи. Итерация через `PriorityQueue` выполняется за **O(n)**.
3. **Потокобезопасность:**
  * `PriorityQueue` не является потокобезопасной. Для многопоточных сред существует `PriorityBlockingQueue`, который обеспечивает синхронизированный доступ.
4. **Использование компаратора:**
  * По умолчанию `PriorityQueue` использует естественный порядок элементов (для объектов, реализующих `Comparable`). Однако, можно передать свой `Comparator` при создании очереди для изменения порядка сортировки.

### **Примеры использования методов `PriorityQueue`**

// Создание PriorityQueue с натуральным порядком  
PriorityQueue\<Integer\> pq \= new PriorityQueue\<\>();

// Добавление элементов  
pq.offer(10);  
pq.offer(20);  
pq.offer(5);  // Очередь: \[5, 20, 10\]

// Просмотр минимального элемента  
int minElement \= pq.peek();  // Вернет 5

// Удаление минимального элемента  
int removedElement \= pq.poll();  // Удаляет и возвращает 5

// Проверка наличия элемента  
boolean contains10 \= pq.contains(10);  // true

// Удаление конкретного элемента  
boolean removed \= pq.remove(20);  // true, удаляет 20

	**Внутренние методы `PriorityQueue`**

1. **"Просеивание вверх" (heapify-up):**
  * Этот метод используется при добавлении нового элемента в кучу. Новый элемент помещается в конец массива, и затем происходит сравнение с родительским элементом. Если новый элемент меньше родительского, они меняются местами. Этот процесс повторяется до тех пор, пока не будет восстановлено свойство кучи.
2. **"Просеивание вниз" (heapify-down):**
  * Этот метод используется при удалении корня (минимального элемента) кучи. Последний элемент заменяет корень, и затем происходит его сравнение с дочерними элементами. Если он больше дочернего, они меняются местами. Этот процесс продолжается, пока не будет восстановлено свойство кучи.

### **Заключение**

`PriorityQueue` — это эффективная реализация очереди с приоритетами в Java, использующая структуру минимальной двоичной кучи. Она обеспечивает логарифмическую сложность для основных операций вставки и удаления, что делает ее подходящей для задач, где требуется динамическое управление элементами в порядке приоритета. Однако, из\-за отсутствия потокобезопасности и гарантий порядка при итерации, нужно выбирать эту структуру данных с учетом конкретных требований приложения.

## Почему операции добавления и извлечения PriorityQueue выполняются за O(log n) ?

Операции добавления и извлечения элементов в `PriorityQueue` выполняются за время **O(log n)**, потому что эта структура данных реализована на основе **двоичной кучи** (binary heap).

### **Как работает `PriorityQueue`?**

`PriorityQueue` хранит элементы таким образом, чтобы элемент с наивысшим приоритетом всегда находился в корне (самом верху) кучи. Это позволяет эффективно добавлять элементы и извлекать элемент с наивысшим приоритетом.

#### **1\. Добавление элемента (`offer` или `add`) — O(log n):**

* **Процесс добавления:**
  1. **Добавление нового элемента в конец внутреннего массива (последний уровень дерева):** Новый элемент сначала добавляется в конец внутреннего массива (дерева), что занимает время O(1).
  2. **"Просеивание вверх" (percolate up или bubble up):** Затем элемент "поднимается" вверх по дереву до тех пор, пока не будет найдено правильное место для его вставки (где он будет меньше/больше родителя в зависимости от свойств кучи). Поскольку дерево кучи — это почти полностью сбалансированное бинарное дерево, этот процесс занимает O(log n) времени в худшем случае, где `n` — количество элементов в `PriorityQueue`.

#### **2\. Удаление элемента (`poll` или `remove`) — O(log n):**

* **Процесс удаления:**
  1. **Удаление корня (элемента с наивысшим приоритетом):** Для удаления элемента с наивысшим приоритетом, который находится в корне, `PriorityQueue` сначала заменяет корневой элемент последним элементом дерева (последним элементом внутреннего массива), что занимает время O(1).
  2. **"Просеивание вниз" (percolate down или bubble down):** Затем элемент "опускается" вниз по дереву, чтобы восстановить свойства кучи. Этот процесс также занимает O(log n) времени в худшем случае, так как каждый шаг уменьшает количество узлов для проверки примерно в два раза.

### **Почему именно O(log n)?**

Давайте разберёмся с причинами:

1. **Двоичная куча как почти полностью сбалансированное дерево:**
  * Двоичная куча — это бинарное дерево, где каждый уровень полностью заполнен, за исключением, возможно, последнего уровня. Такое дерево имеет высоту `h`, равную `log(n)` (приблизительно), где `n` — количество узлов (элементов).
  * Это значит, что при добавлении или удалении элемента в худшем случае нужно пройти по высоте дерева `h`, чтобы перестроить кучу.
2. **Операции на каждом уровне:**
  * При добавлении или удалении элемента может потребоваться "подниматься" или "опускаться" по уровням дерева. Количество таких операций пропорционально высоте дерева, которая равна `O(log n)`.

### **Примеры работы операций**

**Пример добавления:**

Если мы добавляем элемент в `PriorityQueue`, например, число `5` в кучу `[1, 3, 6, 8, 10]`, процесс будет следующим:

1. Добавляем `5` в конец массива, получается `[1, 3, 6, 8, 10, 5]`.
2. "Поднимаем" элемент `5` на правильную позицию:
  * Сравниваем с родительским узлом (в данном случае `6`), меняем их местами, так как `5 < 6`.
  * Повторяем процесс до тех пор, пока не найдем правильное место для `5`.

**Пример удаления:**

При извлечении элемента с наивысшим приоритетом (минимального в случае мин-кучи) из `[1, 3, 6, 8, 10, 5]`:

1. Удаляем корень (`1`) и заменяем его последним элементом (`5`).
2. Затем "опускаем" `5` вниз по дереву:
  * Сравниваем с наименьшим из дочерних элементов (`3`), меняем местами, так как `5 > 3`.
  * Повторяем процесс, пока не будет найдено правильное место.

### **Как устроена двоичная куча?**

Для начала, нужно понять, что двоичная куча (binary heap) — это **почти полное бинарное дерево**:

* **Почти полное** означает, что все уровни дерева полностью заполнены, за исключением, возможно, последнего уровня, который заполняется слева направо.
* Куча может быть **минимальной (min-heap)**, где каждый узел меньше или равен своим дочерним узлам, или **максимальной (max-heap)**, где каждый узел больше или равен своим дочерним узлам.

Двоичная куча обычно реализуется с использованием массива, где для любого узла с индексом `i`:

* **Левый дочерний узел** имеет индекс `2 * i + 1`
* **Правый дочерний узел** имеет индекс `2 * i + 2`
* **Родительский узел** имеет индекс `(i - 1) / 2`

### **Пример: Как добавляется элемент в `PriorityQueue`?**

Предположим, у нас есть **минимальная куча** (min-heap) `[1, 3, 6, 8, 10]`, и мы добавляем в нее элемент `5`.

1. **Добавляем элемент в конец массива:**
  * Начальная куча: `[1, 3, 6, 8, 10]`
  * Добавляем элемент `5` в конец: `[1, 3, 6, 8, 10, 5]`
2. **Поднимаем элемент вверх (heapify up):**  
   Теперь нам нужно поднять элемент `5` на правильную позицию, чтобы поддерживать свойства минимальной кучи:
  * **Сравниваем с родительским узлом:**
    * Индекс `5` — это `5`, его **родительский узел** находится по индексу `(5 - 1) / 2 = 2` (то есть `6`).
    * Сравниваем `5` с `6`. Поскольку `5 < 6`, нужно поменять их местами.
  * После обмена: `[1, 3, 5, 8, 10, 6]`
  * Теперь `5` находится на индексе `2`. Его новый родитель находится по индексу `(2 - 1) / 2 = 0` (то есть `1`).
  * Сравниваем `5` с `1`. Поскольку `5 > 1`, больше не нужно подниматься вверх — вставка завершена.

### **Почему сравниваем с родительским узлом?**

Важно сравнивать **непосредственно с родительским узлом**, а не с любым другим элементом:

* Для поддержания свойства кучи (каждый узел должен быть больше или меньше своего родителя), нужно поднимать элемент вверх по дереву и менять местами с его родительским узлом, если это необходимо.
* Сравнение с элементом `10` (который является правым дочерним узлом узла `3`) не имеет смысла, потому что мы ищем правильную позицию для нового элемента `5` в контексте всего дерева.

### **Пример: Как удаляется элемент из `PriorityQueue`?**

Теперь разберём, как происходит удаление элемента с наивысшим приоритетом (наименьшего для `min-heap`).

1. **Удаляем корневой элемент:**  
   Исходная куча: `[1, 3, 5, 8, 10, 6]`
  * Корень (`1`) — это элемент с наивысшим приоритетом.
  * Чтобы удалить его, заменяем корень последним элементом кучи: `[6, 3, 5, 8, 10]`
2. **Опускаем элемент вниз (heapify down):**  
   Теперь нужно опустить элемент `6` вниз по дереву, чтобы восстановить свойства кучи:
  * Сравниваем `6` с его дочерними элементами `3` и `5`.
  * Берем наименьший дочерний элемент (в данном случае `3`).
  * Поскольку `6 > 3`, меняем их местами: `[3, 6, 5, 8, 10]`.
  * Теперь элемент `6` находится на индексе `1`, его дочерние элементы — `8` и `10`. Поскольку `6` меньше обоих, перестановки не требуются.

Таким образом, `PriorityQueue` всегда поддерживает порядок, необходимый для эффективного извлечения элемента с наивысшим приоритетом за время `O(log n)`.

## ArrayDeque

`ArrayDeque` в Java — это структура данных, представляющая собой двухстороннюю очередь (*double-ended queue*), которая поддерживает вставку и удаление элементов как с начала, так и с конца очереди. `ArrayDeque` не имеет ограничений на размер (в отличие от `ArrayBlockingQueue`), и его внутреннее представление оптимизировано для работы как со стеком, так и с очередью.

### **Основы работы `ArrayDeque`**

1. **Внутреннее представление:**
  * `ArrayDeque` реализована с использованием **динамического массива**. Под капотом это массив объектов `Object[]`, который используется для хранения элементов.
  * Массив **кольцевой**: это означает, что если очередь заполняется в конце, она может продолжить заполняться с начала массива, если там есть свободное место. Это позволяет эффективно использовать память и избегать частых операций расширения массива.
  * Индексы начала (`head`) и конца (`tail`) управляют тем, откуда будут добавляться или удаляться элементы.
2. **Резервирование места (Capacity и Size):**
  * `Capacity` — это текущий размер внутреннего массива, который увеличивается по мере необходимости.
  * `Size` — это текущее количество элементов в `ArrayDeque`.
  * Начальная емкость по умолчанию составляет 16 элементов, и она увеличивается автоматически по мере необходимости, удваиваясь при переполнении.
3. **Ресайз массива:**
  * Когда массив заполняется полностью, `ArrayDeque` удваивает свой размер и копирует все элементы в новый массив. Это занимает **O(n)** времени, но происходит нечасто, поэтому амортизированная сложность операций остается низкой.

### **Время выполнения операций**

* **Добавление элемента в начало (`addFirst`/`offerFirst`):**
  * `addFirst(E e)` или `offerFirst(E e)`: Добавление элемента в начало очереди выполняется за **O(1)**. Элемент добавляется перед текущим `head`, и `head` уменьшается. Если `head` достигает 0, он перемещается к последнему индексу массива (кольцевая очередь).
* **Добавление элемента в конец (`addLast`/`offerLast`):**
  * `addLast(E e)` или `offerLast(E e)`: Добавление элемента в конец очереди также выполняется за **O(1)**. Элемент добавляется после текущего `tail`, и `tail` увеличивается. Если `tail` достигает конца массива, он перемещается в начало (кольцевая очередь).
* **Удаление элемента с начала (`removeFirst`/`pollFirst`):**
  * `removeFirst()` или `pollFirst()`: Удаление элемента из начала очереди выполняется за **O(1)**. Элемент удаляется из позиции `head`, и `head` увеличивается. Если `head` достигает конца массива, он перемещается в начало.
* **Удаление элемента с конца (`removeLast`/`pollLast`):**
  * `removeLast()` или `pollLast()`: Удаление элемента из конца очереди выполняется за **O(1)**. Элемент удаляется с позиции `tail`, и `tail` уменьшается. Если `tail` достигает 0, он перемещается к последнему индексу массива.
* **Просмотр элемента в начале (`getFirst`/`peekFirst`):**
  * `getFirst()` или `peekFirst()`: Возвращает элемент в начале очереди без его удаления. Это **O(1)** операция.
* **Просмотр элемента в конце (`getLast`/`peekLast`):**
  * `getLast()` или `peekLast()`: Возвращает элемент в конце очереди без его удаления. Это **O(1)** операция.
* **Удаление конкретного элемента (`remove`/`removeFirstOccurrence`/`removeLastOccurrence`):**
  * `remove(Object o)`: Эта операция требует линейного поиска по внутреннему массиву и удаления элемента, что в худшем случае имеет сложность **O(n)**.

### **Дополнительные особенности**

1. **Двухсторонняя очередь:**
  * `ArrayDeque` предоставляет операции для добавления и удаления элементов как с начала, так и с конца очереди. Это делает его идеальным для использования в качестве как **очереди (FIFO)**, так и **стека (LIFO)**.
2. **Потокобезопасность:**
  * `ArrayDeque` не является потокобезопасной структурой данных. Для многопоточной среды можно использовать `ConcurrentLinkedDeque` или синхронизацию вручную.
3. **Эффективность:**
  * `ArrayDeque` быстрее, чем `Stack` для реализации стека и быстрее, чем `LinkedList` для реализации очереди, поскольку операции добавления и удаления выполняются за O(1) без накладных расходов на поддержку ссылок, как в `LinkedList`.
4. **Запрет `null` элементов:**
  * `ArrayDeque` не допускает `null` элементов, так как это может вызвать неоднозначность в определении конца очереди.
5. **Итерация:**
  * Итерация через `ArrayDeque` выполняется за **O(n)**. Элементы возвращаются в порядке от `head` до `tail`.

### **Примеры использования методов `ArrayDeque`**

ArrayDeque\<Integer\> deque \= new ArrayDeque\<\>();

// Добавление элементов в начало и конец  
deque.addFirst(1);  // Очередь: \[1\]  
deque.addLast(2);   // Очередь: \[1, 2\]  
deque.offerFirst(0);  // Очередь: \[0, 1, 2\]

// Просмотр элементов  
int first \= deque.getFirst();  // Вернет 0  
int last \= deque.getLast();    // Вернет 2

// Удаление элементов  
deque.removeFirst();  // Удаляет 0, очередь: \[1, 2\]  
deque.pollLast();     // Удаляет 2, очередь: \[1\]

// Проверка наличия элемента  
boolean contains1 \= deque.contains(1);  // true

// Итерация  
for (int num : deque) {  
System.out.println(num);  // Печатает 1  
}

### **Внутренние методы `ArrayDeque`**

1. **Ресайз массива:**
  * Когда `ArrayDeque` заполняется, его размер удваивается. При этом элементы копируются в новый массив. Во время копирования учитывается, что `head` может быть в начале, а `tail` — в конце массива (и наоборот). Все элементы копируются в правильном порядке для сохранения непрерывного представления очереди.
2. **Кольцевой буфер:**
  * При добавлении или удалении элементов `ArrayDeque` использует кольцевой буфер для оптимизации времени выполнения. Когда указатели `head` или `tail` достигают конца массива, они "перепрыгивают" в начало, что позволяет эффективно использовать пространство.

### **Заключение**

`ArrayDeque` — это мощная и эффективная структура данных в Java, которая предоставляет реализацию двухсторонней очереди на основе динамического массива. Благодаря кольцевому буферу и эффективным операциям вставки и удаления `ArrayDeque` является лучшим выбором для задач, требующих как очереди, так и стека, особенно в однопоточной среде. По сравнению с другими коллекциями, такими как `LinkedList` и `Stack`, `ArrayDeque` предлагает высокую производительность и гибкость.

# Set (Interface)

1. HashSet
  1. LinkedHashSet
2. SortedSet (Interface)
  1. TreeSet
3. EnumSet

## HashSet \- уникальные значение, порядок добавления не сохраняется. Позволяет хранить NULL.

`HashSet` — это одна из наиболее часто используемых реализаций интерфейса `Set` в Java. Он обеспечивает быстрое выполнение операций вставки, удаления и поиска элементов благодаря использованию **хеш-таблицы** под капотом.

### **Как работает `HashSet` под капотом?**

`HashSet` основан на использовании экземпляра `HashMap` для хранения данных. Каждое добавленное в `HashSet` значение фактически сохраняется как **ключ** в `HashMap`, а значением для всех этих ключей является статический объект-заглушка `PRESENT`.

#### **Основные особенности работы `HashSet`:**

1. **Внутреннее представление**:
  * `HashSet` использует **хеш-таблицу** для хранения элементов. Под капотом он полагается на `HashMap`, где все элементы `HashSet` выступают в роли ключей этой `HashMap`.
  * Хеш-таблица состоит из **бинов** (buckets), каждый из которых представляет собой ячейку, в которой могут храниться один или несколько элементов. Эти элементы попадают в одну ячейку в случае **хеш-коллизии** (когда несколько элементов имеют одинаковое значение хеш-кода).
2. **Хеширование и индексация**:
  * Каждый добавляемый в `HashSet` элемент сначала проходит через метод `hashCode()`, чтобы получить целочисленное значение хеш-кода.
  * Этот хеш-код затем используется для вычисления индекса в массиве бинов (хеш-таблице) с помощью операции `hashCode % capacity`.
  * На вычисленный индекс помещается элемент. Если ячейка уже занята другим элементом, используется метод цепочек (связанные списки) или бинарные деревья для разрешения коллизий.
3. **Равенство элементов**:
  * При добавлении элемента `HashSet` проверяет, не содержится ли элемент уже в множестве. Это достигается с помощью методов `hashCode()` и `equals()`:
    * Сначала вычисляется хеш-код элемента и находится соответствующий ему бин.
    * Затем сравниваются элементы в этом бине методом `equals()`, чтобы найти возможные дубликаты.

### Размер хеш-таблицы

Размер хеш-таблицы в `HashSet` (а точнее, в используемом под капотом `HashMap`) определяется его **емкостью (capacity)**. Емкость — это текущий размер внутреннего массива, используемого для хранения бинов (buckets), в которые распределяются элементы.

#### Как определяется размер хеш-таблицы?

1. **Начальная емкость**:
  * По умолчанию начальная емкость для `HashSet` (и `HashMap`) равна **16**.
  * Эта емкость задает количество бинов, доступных в хеш-таблице для распределения элементов.
2. **Коэффициент загрузки (load factor)**:
  * Коэффициент загрузки (load factor) по умолчанию равен **0.75**. Это число указывает, насколько может быть заполнена хеш-таблица до того, как произойдет ее увеличение.
  * Когда количество элементов в `HashSet` достигает значения `capacity * loadFactor` (например, 16 \* 0.75 \= 12), происходит **рехеширование** (увеличение размера хеш-таблицы).
3. **Изменение размера (рехеширование)**:
  * Когда число элементов превышает порог `capacity * loadFactor`, `HashSet` автоматически **увеличивает размер хеш-таблицы** в два раза.
  * Например, если текущая емкость была 16, то после достижения порога будет установлена новая емкость 32 и произойдет перераспределение всех элементов в новую таблицу.

#### Пример расчета размера и порога

* **Начальный размер**: 16
* **Коэффициент загрузки**: 0.75
* **Порог увеличения емкости**: `16 * 0.75 = 12`

Когда в `HashSet` будет добавлено 12-й элемент, произойдет увеличение емкости хеш-таблицы до 32\.

#### Краткий ответ: какой размер?

* **По умолчанию** начальный размер хеш-таблицы в `HashSet` равен **16**.
* Этот размер автоматически **удваивается** каждый раз, когда количество элементов превышает порог `capacity * loadFactor`.

### **Время выполнения операций в `HashSet`**

* **Вставка (`add`)**: В среднем `O(1)`, но может достигать `O(n)` в худшем случае (например, когда все элементы попадают в один и тот же бин из\-за плохого хеш-кода или при необходимости перераспределения).
* **Удаление (`remove`)**: В среднем `O(1)`, но в худшем случае — `O(n)`, по тем же причинам.
* **Поиск (`contains`)**: В среднем `O(1)`, но в худшем случае — `O(n)`.

Все эти операции зависят от:

* качества функции `hashCode()`,
* текущей загрузки множества (`load factor`),
* распределения элементов по хеш-таблице (число коллизий).

### **Как реализуются основные операции в `HashSet`?**

1. **Добавление элемента (`add(E e)`)**:
  * Вычисляется хеш-код элемента с помощью `hashCode()`.
  * Определяется бин (bucket), в который следует поместить элемент.
  * Проверяется, есть ли уже в этом бине элемент с таким же значением (`equals`).
    * Если элемента нет, он добавляется.
    * Если элемент уже есть, то ничего не добавляется, метод возвращает `false`.
2. **Удаление элемента (`remove(Object o)`)**:
  * Вычисляется хеш-код элемента.
  * Определяется бин (bucket), из которого нужно удалить элемент.
  * Выполняется поиск элемента внутри этого бина методом `equals`.
  * Если элемент найден, он удаляется, иначе метод возвращает `false`.
3. **Проверка наличия элемента (`contains(Object o)`)**:
  * Вычисляется хеш-код элемента.
  * Определяется бин (bucket), в котором элемент должен находиться.
  * Выполняется проверка на наличие элемента в этом бине методом `equals`.

### **Пример работы `HashSet` под капотом**

Рассмотрим пример использования `HashSet` и разберем, как происходит добавление элемента.

1. **Вычисление хеш-кода**:
  * Вызов метода `"Apple".hashCode()` возвращает значение, например, `63510230`.
2. **Определение индекса**:
  * Пусть текущая емкость хеш-таблицы `HashSet` равна 16\.
  * Индекс вычисляется как `63510230 % 16`, например, `14`.
3. **Добавление в хеш-таблицу**:
  * Проверяется бин с индексом 14\. Если он пуст, элемент добавляется.
  * Если в этом бине уже есть элементы (коллизия), то новый элемент добавляется в связанный список или используется бинарное дерево для поиска подходящей позиции.

### **Важные аспекты и рекомендации при использовании `HashSet`**

1. **Качество хеш-функции**:
  * Очень важно, чтобы метод `hashCode()` был правильно реализован и распределял значения равномерно по хеш-таблице, чтобы минимизировать коллизии.
2. **`equals()` и `hashCode()`**:
  * Необходимо переопределять методы `equals()` и `hashCode()` в классе элементов, если требуется особое поведение сравнения объектов.
3. **Резервирование (`capacity`) и коэффициент загрузки (`load factor`)**:
  * Коэффициент загрузки по умолчанию равен 0.75, что является хорошим компромиссом между использованием памяти и производительностью.
  * При увеличении размера `HashSet` (например, в случае большого количества элементов) важно учитывать увеличение памяти, требуемой для хранения и перераспределения элементов.

### **Связанный список vs бинарное дерево**

В `HashSet` (и `HashMap`, который используется под капотом `HashSet`) для хранения элементов в одном бине (bucket) используется либо **связанный список**, либо **бинарное дерево** (красно-черное дерево) в зависимости от количества элементов, попавших в один и тот же бин.

#### Когда используется связанный список?

Связанный список используется по умолчанию для хранения элементов в бине, если количество элементов (коллизий) в этом бине **меньше определенного порогового значения**.

* **По умолчанию, если количество элементов в бине меньше 8**, используется связанный список.
* Это делается для экономии памяти и минимизации накладных расходов на поддержание сложной структуры данных, такой как дерево, если количество элементов в бине невелико.

#### Когда используется бинарное дерево?

Если количество элементов в бине превышает пороговое значение (по умолчанию 8), то **связанный список автоматически преобразуется в бинарное дерево** (красно-черное дерево).

* **Пороговое значение для преобразования**: если количество элементов в бине становится **8 или больше**, то связанный список преобразуется в бинарное дерево.
* **Пороговое значение для обратного преобразования**: если количество элементов в бине уменьшается до **6 или меньше** после удаления элементов, бинарное дерево обратно преобразуется в связанный список.

#### Почему и когда происходит преобразование?

1. **Преобразование в бинарное дерево**:
  * Когда в одном бине накапливается **8 и более элементов**, время поиска в связанном списке становится `O(n)`, что может замедлить работу `HashSet`.
  * Преобразование в красно-черное дерево (самобалансирующееся бинарное дерево) позволяет сократить время поиска, вставки и удаления элементов до `O(log n)`.
2. **Преобразование обратно в связанный список**:
  * Если количество элементов в бине становится меньше **6** (например, при удалении элементов), структура данных преобразуется обратно в связанный список. Это сделано для экономии памяти, так как бинарное дерево занимает больше памяти, чем связанный список.
  * Пороговое значение 6 установлено для предотвращения частых преобразований между списком и деревом при малых изменениях в числе элементов.

#### Пример работы с преобразованиями

Предположим, у нас есть хеш-таблица с биномиальным массивом емкости 16, и много объектов попали в один и тот же бин (из-за коллизий).

1. **Добавление 7-го элемента в бин**:
  * Элементы по-прежнему хранятся в связанном списке, потому что их количество меньше 8\.
2. **Добавление 8-го элемента в тот же бин**:
  * При добавлении 8-го элемента связанный список **преобразуется в бинарное дерево**.
3. **Удаление нескольких элементов, оставляя 6 в бине**:
  * Если количество элементов уменьшается до 6 или меньше, бинарное дерево преобразуется обратно в связанный список.

#### Важные пороги в `HashMap`/`HashSet` (Java 8+)

* **TREEIFY\_THRESHOLD \= 8**: преобразование в дерево, если количество элементов в бине достигает 8\.
* **UNTREEIFY\_THRESHOLD \= 6**: преобразование обратно в связанный список, если количество элементов в бине становится 6 или меньше.
* **MIN\_TREEIFY\_CAPACITY \= 64**: чтобы хеш-таблица могла быть преобразована в дерево, ее емкость должна быть не менее 64\. Это предотвращает неэффективное использование памяти при малом размере хеш-таблицы.

### **Заключение**

`HashSet` — это мощная и быстрая реализация множества, идеально подходящая для случаев, когда нужно поддерживать уникальность элементов и не важен их порядок. Благодаря внутренней структуре, основанной на `HashMap`, `HashSet` обеспечивает высокую производительность для большинства операций, если используются хорошие хеш-функции.

## LinkedHashSet \- уникальные значения, сохраняет порядок добавления. Позволяет хранить NULL.

`LinkedHashSet` — это реализация интерфейса `Set` в Java, которая сочетает в себе свойства `HashSet` и связного списка. В отличие от `HashSet`, который не гарантирует порядка хранения элементов, `LinkedHashSet` **гарантирует порядок вставки** элементов. Это означает, что элементы в `LinkedHashSet` будут храниться в том порядке, в котором они были добавлены.

### **Как работает `LinkedHashSet` под капотом?**

`LinkedHashSet` работает на основе двух структур данных:

1. **Хеш-таблица** (как в `HashSet`), обеспечивающая быструю вставку, удаление и поиск.
2. **Двухсвязный список**, который хранит порядок вставки элементов.

#### **Основные особенности `LinkedHashSet`**

1. **Порядок вставки**:
  * `LinkedHashSet` сохраняет порядок элементов, добавленных в него. Если добавить элементы `"apple"`, `"banana"`, `"orange"`, то они будут храниться в этом же порядке при итерации.
2. **Поддержание связного списка**:
  * Для поддержания порядка вставки используется **двухсвязный список**, который соединяет все элементы в хеш-таблице в последовательности их добавления. Каждая запись в хеш-таблице содержит ссылки на предыдущий и следующий элемент в списке.
3. **Наследование от `HashSet`**:
  * `LinkedHashSet` наследуется от `HashSet` и использует его внутренние механизмы для работы с хеш-таблицей. Однако для поддержания порядка он также добавляет дополнительные ссылки (`before` и `after`) в каждый элемент, чтобы соединить их в связный список.

### **Подробное устройство `LinkedHashSet`**

1. **Элементы в `LinkedHashSet`**:
  * Внутренне, каждый элемент в `LinkedHashSet` представлен в виде объекта типа `LinkedHashMap.Entry<K, V>`, где ключом (`K`) является элемент множества, а значением (`V`) всегда выступает фиктивное значение (`PRESENT`).
  * Каждый объект `Entry` содержит три важных ссылки:
    * `next` — ссылка на следующий элемент в хеш-таблице (для разрешения коллизий).
    * `before` — ссылка на предыдущий элемент в связном списке.
    * `after` — ссылка на следующий элемент в связном списке.
2. **Структура хеш-таблицы**:
  * Как и в `HashSet`, `LinkedHashSet` использует хеш-таблицу для быстрого доступа к элементам по их хеш-коду.
  * Однако, для сохранения порядка вставки, каждый элемент в хеш-таблице хранит дополнительные ссылки (`before` и `after`), которые связывают элементы в порядке их вставки.
3. **Процесс вставки**:
  * Когда новый элемент добавляется в `LinkedHashSet`, сначала вычисляется его хеш-код, и определяется соответствующий **бин (bucket)** в хеш-таблице.
  * Если элемент уже присутствует (определяется с помощью метода `equals`), то он **не добавляется**.
  * Если элемента нет, он добавляется в хеш-таблицу и в связный список:
    * В конце связного списка устанавливается ссылка `after` на новый элемент.
    * Новый элемент указывает на предыдущий элемент в списке с помощью ссылки `before`.
4. **Процесс удаления**:
  * Удаление элемента также включает две операции:
    * Удаление из хеш-таблицы.
    * Перестроение ссылок `before` и `after` для поддержания связности списка.

### **Время выполнения операций**

* **Вставка (`add`)**: `O(1)` — Время вставки в хеш-таблицу остается константным за счет использования хеширования. Дополнительная работа для поддержания связного списка (`before` и `after`) также выполняется за константное время.
* **Удаление (`remove`)**: `O(1)` — Удаление элемента из хеш-таблицы происходит за константное время, как и обновление ссылок в двухсвязном списке.
* **Поиск (`contains`)**: `O(1)` — Поиск по хеш-таблице занимает константное время, как в `HashSet`.
* **Итерация (`iterator`)**: `O(n)` — Итерация проходит в порядке вставки и требует линейного времени, поскольку элементы связаны в двухсвязный список.

### **Пример работы `LinkedHashSet`**

Set\<String\> linkedHashSet \= new LinkedHashSet\<\>();  
linkedHashSet.add("apple");  
linkedHashSet.add("banana");  
linkedHashSet.add("orange");  
linkedHashSet.add("apple"); // Дубликат, не будет добавлен

System.out.println(linkedHashSet); // Вывод: \[apple, banana, orange\]

* Элементы выводятся в порядке их добавления: `"apple"`, `"banana"`, `"orange"`.
* Порядок остается стабильным при итерации.

### **Заключение**

`LinkedHashSet` — это мощная структура данных, которая предоставляет эффективность `HashSet` с сохранением порядка вставки. Использование внутренней хеш-таблицы и двухсвязного списка позволяет добиться времени `O(1)` для вставки, удаления и поиска, при этом сохраняя элементы в порядке их добавления.

## TreeSet \- самобалансирующее бинарное дерево поиска. Не позволяет хранить NULL.

`SortedSet` — это интерфейс в Java, который расширяет интерфейс `Set` и добавляет поведение, гарантирующее **отсортированный порядок** элементов в наборе. `SortedSet` является интерфейсом, и его основная реализация в Java — это `TreeSet`.

Давай разберем, как работает `TreeSet`, чтобы понять, как `SortedSet` организует свои элементы и какие временные затраты на основные операции.

### **Как работает `TreeSet` под капотом?**

`TreeSet` основан на **самобалансирующемся бинарном дереве поиска**, конкретно — на **красно-черном дереве**. Красно-черное дерево — это вид бинарного дерева поиска, который автоматически балансируется при выполнении операций вставки и удаления, чтобы обеспечить логарифмическое время выполнения.

#### **Основные характеристики `TreeSet`**

1. **Порядок элементов**:
  * Элементы хранятся в отсортированном порядке, который определяется либо **естественным порядком** (`Comparable`), либо переданным в конструктор **компаратором** (`Comparator`).
  * `TreeSet` не позволяет хранить `null` элементы, поскольку они не могут быть сравнены для поддержания порядка.
2. **Использование красно-черного дерева**:
  * Под капотом `TreeSet` использует `NavigableMap`, в частности, `TreeMap` для хранения элементов. `TreeMap` реализован на основе красно-черного дерева.
  * В `TreeSet` элементы являются ключами этого `TreeMap`, а значение всегда является фиктивным (`PRESENT`).
3. **Преимущества красно-черного дерева**:
  * Красно-черное дерево гарантирует, что высота дерева всегда остается `O(log n)`, что обеспечивает **логарифмическое время выполнения** для основных операций (вставка, удаление, поиск).

### **Как работают основные операции?**

1. **Вставка (`add`)**:
  * При добавлении нового элемента `TreeSet` вычисляет его положение в дереве путем сравнения с существующими элементами (используя метод `compareTo()` или переданный `Comparator`).
  * Если элемент уже существует, то он не добавляется (поскольку `Set` не допускает дубликатов).
  * В худшем случае вставка занимает `O(log n)` времени из\-за необходимости прохода по дереву и возможной перестройки узлов для поддержания баланса.
2. **Удаление (`remove`)**:
  * Удаление элемента также требует поиска его положения в дереве, что занимает `O(log n)` времени.
  * После нахождения элемента выполняется удаление и, если необходимо, **ребалансировка дерева** для сохранения его свойств.
3. **Поиск (`contains`)**:
  * Проверка наличия элемента в `TreeSet` также выполняется за `O(log n)` времени, так как она требует поиска элемента по дереву.
4. **Итерация (`iterator`)**:
  * Итерирование по элементам в `TreeSet` выполняется в **отсортированном порядке**, начиная с самого малого элемента и заканчивая самым большим.
  * Итерация по дереву занимает `O(n)` времени, так как требуется пройти через все узлы дерева.

### **Дополнительные операции `SortedSet`**

`SortedSet` предоставляет дополнительные методы, которые позволяют извлекать части набора и работать с диапазонами:

* **`first()` и `last()`**: возвращают первый (наименьший) и последний (наибольший) элементы в наборе соответственно. Эти операции занимают `O(log n)` времени, так как связаны с крайними узлами дерева.
* **`headSet(toElement)`**: возвращает `SortedSet`, содержащий все элементы, **меньшие `toElement`**. Эта операция выполняется за `O(log n)` времени для поиска начального узла, но фактическая итерация по подмножеству занимает `O(k)`, где `k` — количество элементов в подмножестве.
* **`tailSet(fromElement)`**: возвращает `SortedSet`, содержащий все элементы, **большие или равные `fromElement`**. Работает аналогично `headSet`.
* **`subSet(fromElement, toElement)`**: возвращает `SortedSet` из элементов между `fromElement` (включительно) и `toElement` (исключительно). Время выполнения операции аналогично `headSet` и `tailSet`.

### **Временные затраты операций `TreeSet`**

* **Вставка (`add`)**: `O(log n)`
* **Удаление (`remove`)**: `O(log n)`
* **Поиск (`contains`)**: `O(log n)`
* **Итерация (`iterator`)**: `O(n)`
* **Получение первого/последнего элемента (`first()`/`last()`)**: `O(log n)`
* **Получение подмножества (`headSet()`, `tailSet()`, `subSet()`)**: `O(log n)` для начала \+ `O(k)` для итерации

### **Пример использования `TreeSet`**

import java.util.\*;

public class TreeSetExample {

    public static void main(String\[\] args) {

        SortedSet\<Integer\> treeSet \= new TreeSet\<\>();

        

        treeSet.add(5);

        treeSet.add(2);

        treeSet.add(8);

        treeSet.add(1);

        treeSet.add(3);

        System.out.println("TreeSet (в отсортированном порядке): " \+ treeSet); // \[1, 2, 3, 5, 8\]

        System.out.println("Первый элемент: " \+ treeSet.first()); // 1

        System.out.println("Последний элемент: " \+ treeSet.last()); // 8

        SortedSet\<Integer\> headSet \= treeSet.headSet(5);

        System.out.println("Элементы меньше 5: " \+ headSet); // \[1, 2, 3\]

        SortedSet\<Integer\> tailSet \= treeSet.tailSet(3);

        System.out.println("Элементы больше или равны 3: " \+ tailSet); // \[3, 5, 8\]

    }

}

### **Заключение**

`SortedSet` (реализованный через `TreeSet`) использует красно-черное дерево для поддержания отсортированного порядка элементов, обеспечивая `O(log n)` время выполнения для операций вставки, удаления и поиска. Это делает `TreeSet` отличным выбором, когда требуется хранить элементы в отсортированном порядке и быстро выполнять операции поиска и изменения.

# Map

## HashMap

`HashMap` — это одна из наиболее популярных реализаций интерфейса `Map` в Java, использующая хеш-таблицу для хранения элементов. Она предоставляет быстрый доступ к элементам за счет хеширования ключей. Давайте рассмотрим, как она работает под капотом и какие операции имеют какие временные характеристики.

### **Основы работы `HashMap`**

1. **Хеш-таблица:**
  * `HashMap` использует внутреннюю **хеш-таблицу** (`Node<K,V>[] table`), которая представляет собой массив бакетов (корзин) для хранения элементов.
  * Каждый бакет представляет собой связанный список (или деревья в случае сильной коллизии), в котором хранятся пары "ключ-значение".
2. **Хеширование:**
  * При добавлении элемента, `HashMap` вычисляет хеш-код ключа с помощью метода `hashCode()`.
  * Хеш-код преобразуется в индекс в массиве бакетов с помощью функции хеширования. Это помогает определить, в какой бакет вставить элемент.
  * Индекс рассчитывается как `(n - 1) & hash` (где `n` — размер массива, а `hash` — хеш-код ключа), что позволяет равномерно распределить элементы.
3. **Коллизии:**
  * Если два ключа имеют одинаковый хеш-код (коллизия), то элементы будут храниться в виде связанного списка в одном бакете.
  * Для уменьшения времени поиска при сильных коллизиях начиная с JDK 8, длинные списки заменяются на сбалансированные деревья (красно-черные деревья) для улучшения производительности.
4. **Расширение и перераспределение:**
  * Когда количество элементов в `HashMap` достигает определенного порога загрузки (`load factor`, по умолчанию 0.75), массив бакетов расширяется.
  * При расширении массива (удвоение размера) происходит перераспределение всех существующих элементов по новым бакетам, что может быть затратным по времени.

### **Временные характеристики операций**

1. **Вставка элемента (`put(K key, V value)`):**
  * Вставка элемента выполняется в среднем за **O(1)**.
  * Сначала вычисляется индекс бакета с помощью хеш-функции.
  * Если бакет пустой, создается новый узел и помещается в бакет.
  * Если бакет уже содержит элементы, выполняется поиск по связанному списку (или дереву), чтобы проверить, существует ли уже элемент с таким ключом. Если ключ уже существует, его значение обновляется; если нет, добавляется новый узел.
  * В случае коллизии и необходимости расширения, вставка может быть временно более затратной.
2. **Получение значения по ключу (`get(Object key)`):**
  * Получение значения выполняется в среднем за **O(1)**.
  * Сначала вычисляется индекс бакета с помощью хеш-функции.
  * Поиск элемента по ключу выполняется в связанном списке (или дереве) в соответствующем бакете.
3. **Удаление элемента (`remove(Object key)`):**
  * Удаление элемента выполняется в среднем за **O(1)**.
  * Сначала вычисляется индекс бакета с помощью хеш-функции.
  * Поиск элемента по ключу в соответствующем бакете и удаление его из связанного списка (или дерева) при нахождении.
4. **Проверка наличия ключа (`containsKey(Object key)`):**
  * Проверка наличия ключа выполняется в среднем за **O(1)**.
  * Сначала вычисляется индекс бакета с помощью хеш-функции.
  * Поиск элемента по ключу выполняется в связанном списке (или дереве) в соответствующем бакете.
5. **Проверка наличия значения (`containsValue(Object value)`):**
  * Проверка наличия значения выполняется в среднем за **O(n)**.
  * Для проверки наличия значения необходимо пройти по всем бакетам и по всем элементам в каждом бакете, что делает операцию линейной.
6. **Перераспределение и расширение:**
  * Перераспределение и расширение происходит, когда количество элементов превышает порог загрузки.
  * Операция расширения выполняется за **O(n)**, так как необходимо перераспределить все элементы по новым бакетам.

### **Примеры использования методов `HashMap`**

import java.util.HashMap;  
import java.util.Map;

public class HashMapExample {  
public static void main(String\[\] args) {  
Map\<String, Integer\> map \= new HashMap\<\>();

        // Вставка элементов  
        map.put("One", 1);  
        map.put("Two", 2);  
        map.put("Three", 3);  
          
        // Получение значения по ключу  
        int value \= map.get("Two");  // Вернет 2  
          
        // Проверка наличия ключа и значения  
        boolean hasKey \= map.containsKey("One");  // true  
        boolean hasValue \= map.containsValue(3);  // true  
          
        // Удаление элемента  
        map.remove("Three");  
          
        // Итерация по ключам и значениям  
        for (Map.Entry\<String, Integer\> entry : map.entrySet()) {  
            System.out.println("Key: " \+ entry.getKey() \+ ", Value: " \+ entry.getValue());  
        }  
    }  
}

### **Внутренние детали**

1. **Реализация хеш-таблицы:**
  * Хеш-таблица реализована с массивом, где каждый элемент массива представляет собой бакет. Каждый бакет может содержать связанный список узлов или сбалансированное дерево для хранения пар "ключ-значение".
2. **Влияние порога загрузки:**
  * Порог загрузки (`load factor`) определяет, когда происходит расширение массива. Если значение по умолчанию 0.75, это означает, что при заполнении 75% текущих бакетов происходит расширение.
3. **Устранение коллизий:**
  * Коллизии решаются с помощью связанных списков или сбалансированных деревьев. Сбалансированные деревья используются, если длина связанного списка в бакете превышает определенное пороговое значение.

### **Заключение**

`HashMap` — это эффективная реализация интерфейса `Map`, предоставляющая быстрый доступ к элементам за счет хеширования ключей. Основные операции вставки, удаления и получения значений выполняются в среднем за **O(1)**, но могут занимать больше времени в случае коллизий или расширения. `HashMap` обеспечивает высокую производительность для общего использования, но не гарантирует порядок элементов.

## Пример реализации

Давайте разберем, как работает `HashMap` под капотом, когда мы выполняем следующие операции:  
Map\<Integer, String\> map \= new HashMap\<\>();  
map.put(1, "First");  
map.put(2, "Second");  
map.put(3, "Third");

### **1\. Инициализация `HashMap`**

Map\<Integer, String\> map \= new HashMap\<\>();

Когда создается новый объект `HashMap` без указания начальной емкости и коэффициента загрузки, используются значения по умолчанию:

* **Начальная емкость** (`initial capacity`): 16\.
* **Коэффициент загрузки** (`load factor`): 0.75.

Это означает, что хеш-таблица внутри `HashMap` будет представлять собой массив с 16 бакетами, и при заполнении 75% от 16 (то есть 12 элементов) произойдет увеличение размера хеш-таблицы в 2 раза.

### **2\. Операция `put(1, "First")`**

map.put(1, "First");

Когда мы вызываем метод `put`, выполняются следующие шаги:

1. **Вычисление хеш-кода:**
  * Для ключа `1` вызывается метод `hashCode()`, который возвращает `1` (хеш-код для объекта типа `Integer` с значением `1` равен `1`).
2. **Применение хеш-функции:**
  * Хеш-код `1` преобразуется в индекс массива (бакета) с помощью метода `hash(int h)`, который использует битовое смещение и XOR:

static final int hash(Object key) {  
int h;  
return (key \== null) ? 0 : (h \= key.hashCode()) ^ (h \>\>\> 16);  
}

* В результате, для хеш-кода `1`, индекс бакета вычисляется как `(1 ^ (1 >>> 16)) & (n - 1)`, где `n` — текущий размер массива (16). Это даст индекс `1`.

**Проверка бакета:**

* `HashMap` проверяет бакет с индексом `1`. Поскольку бакет пуст (нет узлов), создается новый узел (`Node<K, V>`) и помещается в этот бакет.
* Узел содержит 4 поля: `hash` (хеш-код ключа), `key` (ключ), `value` (значение), и `next` (ссылка на следующий узел в случае коллизии).

Node\<Integer, String\> newNode \= new Node\<\>(1, 1, "First", null);  
table\[1\] \= newNode;

### **3\. Операция `put(2, "Second")`**

map.put(2, "Second");

Теперь, когда мы вставляем новый элемент, происходит аналогичный процесс:

1. **Вычисление хеш-кода:**
  * Для ключа `2` метод `hashCode()` возвращает `2`.
2. **Применение хеш-функции:**
  * Хеш-код `2` преобразуется в индекс массива (бакета) с помощью метода `hash(int h)`, аналогично первому случаю:

int hash \= 2 ^ (2 \>\>\> 16); // результат будет также 2

* Индекс бакета будет `(2) & (16 - 1) = 2`.
2. **Проверка бакета:**
  * `HashMap` проверяет бакет с индексом `2`. Этот бакет пуст, поэтому создается новый узел и помещается в этот бакет.

Node\<Integer, String\> newNode \= new Node\<\>(2, 2, "Second", null);  
table\[2\] \= newNode;

### **4\. Операция `put(3, "Third")`**

map.put(3, "Third");

Процесс аналогичен предыдущим вставкам:

1. **Вычисление хеш-кода:**
  * Для ключа `3` метод `hashCode()` возвращает `3`.
2. **Применение хеш-функции:**
  * Хеш-код `3` преобразуется в индекс массива (бакета) с помощью метода `hash(int h)`:  
    int hash \= 3 ^ (3 \>\>\> 16); // результат будет также 3
  * Индекс бакета будет `(3) & (16 - 1) = 3`.
3. **Проверка бакета:**
  * `HashMap` проверяет бакет с индексом `3`. Этот бакет пуст, поэтому создается новый узел и помещается в этот бакет.

Node\<Integer, String\> newNode \= new Node\<\>(3, 3, "Third", null);  
table\[3\] \= newNode;

### **Итоговое состояние `HashMap`**

* Массив бакетов будет выглядеть следующим образом:

| Индекс бакета | Содержимое |
| ----- | ----- |
| 0 | `null` |
| 1 | `Node(1, "First")` |
| 2 | `Node(2, "Second")` |
| 3 | `Node(3, "Third")` |
| 4-15 | `null` |

Каждый из узлов (`Node`) содержит информацию о ключе, значении и ссылку на следующий элемент (в данном случае `null`).

### **Заключение**

Под капотом `HashMap` использует хеширование для быстрого вычисления индекса массива (бакета) и хранения элементов в этих бакетах. Каждый вызов `put()` включает в себя вычисление хеш-кода, вычисление индекса, проверку бакета и добавление нового узла. Время выполнения этих операций в среднем составляет **O(1)**, но в случае коллизий или перераспределения элементов оно может увеличиться.

## Почему сразу не использовать красно-черное дерево вместо связанного списка, если поиск по дереву за O(log n), а по связанному списку О(N)?

На самом деле, использование красно-черного дерева вместо связанного списка в `HashMap` для обработки коллизий могло бы улучшить производительность в худших случаях. Однако есть несколько причин, почему `HashMap` сначала использует связный список и только затем переключается на красно-черное дерево, если длина списка превышает определенный порог (в JDK 8 это порог равен 8).

### **Причины использования связного списка до порога:**

1. **Памятная эффективность**:
  * Связный список использует меньше памяти на один узел по сравнению с красно-черным деревом. Каждый узел списка хранит только ссылку на следующий элемент, тогда как узел дерева хранит больше метаданных (ссылки на родительский узел, левое и правое поддерево, информацию о цвете и т.д.).
  * При малом числе элементов (например, до 8\) связный список является более эффективным по памяти и не требует дополнительных ресурсов для управления структурой дерева.
2. **Низкая вероятность коллизий**:
  * В правильно распределенной хеш-таблице коллизии происходят редко, и обычно в одном бакете оказывается не более одного или нескольких элементов. В таком случае, средняя длина связного списка мала (0 или 1 элемент), и поиск в нем фактически работает за **O(1)**.
  * Если количество элементов в бакете мало (например, 2-3 элемента), поиск в связном списке по времени оказывается таким же быстрым или даже быстрее, чем в дереве, из\-за более низких накладных расходов на поддержку структуры дерева.
3. **Простота и скорость вставки**:
  * Вставка нового элемента в связный список проще и быстрее. Нужно всего лишь добавить элемент в начало или конец списка. В то время как вставка в красно-черное дерево требует выполнения операций по балансировке дерева, что добавляет дополнительные накладные расходы.
  * Для большинства реальных задач, где количество элементов в одном бакете остается небольшим, вставка и поиск в связном списке быстрее, чем вставка и поддержка сбалансированного дерева.
4. **Низкие накладные расходы при небольшой длине цепочки**:
  * Поддержка связного списка требует минимальных накладных расходов по сравнению с деревом. В большинстве случаев доступ к элементу занимает константное время **O(1)**, и переключение на красно-черное дерево может быть неоправданным при небольшом количестве элементов.
5. **Сложность реализации и отладка**:
  * Связный список легче реализовать и отладить. Вставка и удаление в связном списке проще, так как не требуется выполнять повороты и поддерживать балансировку.

### **Почему переключаются на красно-черное дерево при определенном пороге?**

Когда количество элементов в одном бакете становится достаточно большим (например, 8 и более), использование связного списка для поиска и вставки становится медленным, и сложность операций переходит в **O(n)**. В таких случаях красно-черное дерево позволяет существенно улучшить производительность, снижая сложность до **O(log n)** для поиска, вставки и удаления.

Таким образом, комбинация связного списка и красно-черного дерева в `HashMap` представляет собой гибридный подход, который:

* Сохраняет простоту и эффективность для случаев, когда коллизии маловероятны или их количество невелико.
* Автоматически адаптируется и повышает производительность в случаях, когда в одном бакете оказывается большое количество элементов.

### **Заключение**

Использование связного списка в `HashMap` по умолчанию обеспечивает баланс между памятью и временем выполнения при небольшом количестве элементов в бакетах. Только когда длина цепочки превышает определенный порог, используется красно-черное дерево для оптимизации производительности. Этот подход минимизирует накладные расходы и максимизирует производительность в типичных случаях использования `HashMap`.

## LinkedHashMap

`LinkedHashMap` — это реализация интерфейса `Map`, которая поддерживает порядок вставки или порядок доступа элементов. Этот класс расширяет `HashMap`, добавляя двусвязный список для поддержания порядка элементов. Благодаря этому `LinkedHashMap` гарантирует, что порядок обхода элементов будет таким же, как порядок их вставки или порядок их последнего доступа (в зависимости от конфигурации).

### **Особенности `LinkedHashMap`**

1. **Поддержание порядка элементов**:
  * `LinkedHashMap` поддерживает два типа порядка:
    * **Порядок вставки**: элементы обходятся в том порядке, в котором они были вставлены в карту.
    * **Порядок доступа**: элементы перемещаются в конец, когда к ним происходит доступ (чтение или запись). Это полезно, например, для реализации кэшей с ограниченным размером (LRU-кэш).
2. **Двусвязный список для порядка**:
  * `LinkedHashMap` использует двусвязный список для поддержания порядка элементов. Каждый узел списка содержит ссылки на предыдущий и следующий элемент.
3. **Время выполнения операций**:
  * Как и у `HashMap`, время выполнения основных операций (вставка, удаление, поиск) в `LinkedHashMap` составляет **O(1)** в среднем случае. Однако поддержание двусвязного списка требует дополнительных накладных расходов по памяти.

### **Внутреннее устройство `LinkedHashMap`**

#### **1\. Основные структуры данных**

`LinkedHashMap` наследуется от `HashMap` и добавляет к нему поддержание порядка элементов с помощью двусвязного списка. Ключевые внутренние структуры включают:

* **Хеш-таблица** (как в `HashMap`): массив бакетов, каждый из которых может содержать цепочку элементов при коллизии.
* **Двусвязный список**: для поддержания порядка вставки или доступа элементов. Каждый узел двусвязного списка хранит ссылки на предыдущий и следующий элементы.

#### **2\. Класс `LinkedHashMap.Entry`**

Внутренний класс `LinkedHashMap.Entry<K, V>` расширяет `HashMap.Node<K, V>` и добавляет ссылки на предыдущий и следующий узлы, образуя двусвязный список:

static class Entry\<K,V\> extends HashMap.Node\<K,V\> {  
Entry\<K,V\> before, after;  // Ссылки на предыдущий и следующий узел в двусвязном списке

    Entry(int hash, K key, V value, HashMap.Node\<K,V\> next) {  
        super(hash, key, value, next);  
    }  
}

#### **3\. Поддержание порядка элементов**

* **Порядок вставки**: Каждый раз при добавлении нового элемента в `LinkedHashMap` он добавляется в конец двусвязного списка. Порядок элементов в этом списке соответствует порядку их вставки.
* **Порядок доступа**: Если `LinkedHashMap` сконфигурирован в режиме "по порядку доступа" (через конструктор `LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder)`), то каждый раз при доступе к элементу (вызов метода `get()`, например) элемент перемещается в конец списка.

#### **4\. Основные операции в `LinkedHashMap`**

1. **Вставка (`put`)**:
  * Вставка элемента в `LinkedHashMap` работает так же, как и в `HashMap` для добавления элемента в хеш-таблицу.
  * В случае коллизии `LinkedHashMap` использует тот же механизм разрешения коллизий, что и `HashMap` (связные списки или красно-черные деревья).
  * Дополнительно элемент вставляется в конец двусвязного списка. Это требует изменения ссылок на предыдущий и следующий элементы. Таким образом, время вставки остается **O(1)**.
2. **Поиск (`get`)**:
  * Поиск элемента по ключу аналогичен `HashMap` и выполняется в среднем за **O(1)**.
  * Если включен режим порядка доступа, найденный элемент перемещается в конец двусвязного списка. Время этой операции также **O(1)**, так как список является двусвязным.
3. **Удаление (`remove`)**:
  * Удаление элемента выполняется в среднем за **O(1)**, как и в `HashMap`.
  * Дополнительно `LinkedHashMap` удаляет узел из двусвязного списка, что также требует изменения ссылок на предыдущий и следующий элементы. Эта операция также занимает **O(1)**.
4. **Обход элементов (`entrySet()`, `keySet()`, `values()`)**:
  * Обход элементов в `LinkedHashMap` всегда выполняется в порядке вставки или порядке доступа. Для этого используется двусвязный список, итерирование по которому происходит за **O(n)**.

### **Пример работы `LinkedHashMap`**

Пример кода, демонстрирующего работу `LinkedHashMap`:

import java.util.LinkedHashMap;  
import java.util.Map;

public class LinkedHashMapExample {  
public static void main(String\[\] args) {  
// Создаем LinkedHashMap с порядком вставки  
Map\<String, Integer\> map \= new LinkedHashMap\<\>();

        // Вставляем элементы  
        map.put("First", 1);  
        map.put("Second", 2);  
        map.put("Third", 3);

        // Выводим элементы в порядке вставки  
        System.out.println("LinkedHashMap with insertion order:");  
        for (Map.Entry\<String, Integer\> entry : map.entrySet()) {  
            System.out.println(entry.getKey() \+ ": " \+ entry.getValue());  
        }

        // Доступ к элементу для изменения порядка доступа  
        map.get("First");

        // Создаем LinkedHashMap с порядком доступа  
        Map\<String, Integer\> accessOrderMap \= new LinkedHashMap\<\>(16, 0.75f, true);

        // Вставляем элементы  
        accessOrderMap.put("First", 1);  
        accessOrderMap.put("Second", 2);  
        accessOrderMap.put("Third", 3);

        // Доступ к элементу для изменения порядка доступа  
        accessOrderMap.get("First");

        // Выводим элементы в порядке доступа  
        System.out.println("\\nLinkedHashMap with access order:");  
        for (Map.Entry\<String, Integer\> entry : accessOrderMap.entrySet()) {  
            System.out.println(entry.getKey() \+ ": " \+ entry.getValue());  
        }  
    }  
}

### **Ожидаемый вывод:**

LinkedHashMap with insertion order:  
First: 1  
Second: 2  
Third: 3

LinkedHashMap with access order:  
Second: 2  
Third: 3  
First: 1

### **Заключение**

`LinkedHashMap` сочетает в себе преимущества `HashMap` (высокая производительность операций за **O(1)** в среднем случае) с поддержкой порядка элементов, что делает его полезным для множества практических задач, таких как кэширование (например, LRU-кэш). При этом `LinkedHashMap` имеет дополнительную память для поддержания двусвязного списка и немного большую сложность по сравнению с `HashMap`, но сохраняет отличную производительность благодаря своей гибридной структуре.

## TreeMap

`TreeMap` — это реализация интерфейса `Map` в Java, которая обеспечивает отсортированный порядок хранения элементов на основе их ключей. В отличие от `HashMap`, который не гарантирует порядка хранения, `TreeMap` хранит элементы в отсортированном порядке (естественном порядке ключей или порядке, определенном компаратором).

Под капотом `TreeMap` использует **красно-черное дерево** (self-balancing binary search tree), чтобы обеспечить логарифмическое время выполнения основных операций. Красно-черное дерево гарантирует, что высота дерева остается логарифмической от числа элементов, что позволяет выполнять операции за **O(log n)**.

### **Особенности `TreeMap`**

1. **Основан на красно-черном дереве**:
  * Красно-черное дерево — это сбалансированное двоичное дерево поиска (binary search tree, BST), которое поддерживает балансировку путем перекрашивания узлов и выполнения поворотов во время вставки и удаления.
2. **Отсортированный порядок**:
  * `TreeMap` поддерживает порядок элементов на основе их ключей. Порядок может быть:
    * **Естественный порядок**: определяется методом `compareTo()` ключа (ключ должен реализовывать интерфейс `Comparable`).
    * **Порядок, заданный компаратором**: можно передать `Comparator` в конструктор `TreeMap`.
3. **Навигационные методы**:
  * `TreeMap` предоставляет дополнительные методы для навигации по элементам, такие как `firstKey()`, `lastKey()`, `lowerKey()`, `higherKey()`, `floorKey()`, `ceilingKey()` и другие, которые позволяют быстро находить элементы в отсортированном порядке.

### **Внутреннее устройство `TreeMap`**

#### **1\. Основные структуры данных**

`TreeMap` использует красно-черное дерево для хранения своих элементов, где каждый узел представляет собой пару "ключ-значение". Узлы дерева отсортированы в соответствии с порядком ключей.

* **Класс `TreeMap.Entry`**: внутренний класс, представляющий узел красно-черного дерева. Он содержит ключ, значение, ссылки на левое и правое поддеревья, родительский узел и информацию о цвете узла (красный или черный).

Пример внутреннего класса `Entry`:

static final class Entry\<K,V\> implements Map.Entry\<K,V\> {  
K key;  
V value;  
Entry\<K,V\> left;  
Entry\<K,V\> right;  
Entry\<K,V\> parent;  
boolean color \= BLACK;

    // Конструктор  
    Entry(K key, V value, Entry\<K,V\> parent) {  
        this.key \= key;  
        this.value \= value;  
        this.parent \= parent;  
    }

    // Методы getKey(), getValue(), setValue() и другие  
}

#### **2\. Основные операции в `TreeMap`**

1. **Вставка (`put`)**:
  * Вставка нового элемента в `TreeMap` осуществляется путем поиска подходящей позиции в дереве на основе ключа.
  * Как и в любом двоичном дереве поиска, вставка начинается с корня и продолжается до тех пор, пока не будет найдено подходящее место для нового элемента.
  * После вставки узел окрашивается в красный цвет и могут выполняться повороты и/или перекраски, чтобы поддерживать свойства красно-черного дерева.
  * Время выполнения операции вставки — **O(log n)**.
2. **Поиск (`get`)**:
  * Поиск элемента по ключу начинается с корня дерева и идет вниз по дереву, сравнивая ключ с текущим узлом.
  * Если ключ меньше текущего, поиск продолжается в левом поддереве, если больше — в правом.
  * Поиск завершается, когда находится узел с заданным ключом или достигается конец дерева.
  * Время выполнения операции поиска — **O(log n)**.
3. **Удаление (`remove`)**:
  * Удаление элемента требует нескольких шагов: сначала узел с заданным ключом находится, затем он удаляется, и дерево сбалансировано.
  * Если удаляемый узел имеет два потомка, его значение заменяется минимальным элементом из правого поддерева, а затем этот элемент удаляется.
  * После удаления выполняются повороты и/или перекраски, чтобы сохранить свойства красно-черного дерева.
  * Время выполнения операции удаления — **O(log n)**.
4. **Обход элементов (`entrySet()`, `keySet()`, `values()`)**:
  * Обход элементов в `TreeMap` выполняется в порядке, определенном ключами. Это достигается через симметричный обход (in-order traversal) дерева.
  * Время выполнения обхода элементов — **O(n)**.

### **Балансировка красно-черного дерева**

Красно-черное дерево автоматически балансируется при выполнении операций вставки и удаления. Это достигается с помощью следующих правил:

1. Каждый узел либо красный, либо черный.
2. Корень дерева всегда черный.
3. Все листья (пустые узлы) черные.
4. Красный узел не может иметь красных потомков (нет двух последовательных красных узлов).
5. Любой путь от узла до его листьев содержит одинаковое количество черных узлов.

Если одно из этих правил нарушается в результате вставки или удаления, выполняются операции по исправлению, такие как:

* **Перекраска узлов**.
* **Левый и правый повороты**: операции, которые изменяют структуру дерева и помогают сбалансировать его.

### **Пример работы `TreeMap`**

Пример кода, демонстрирующего работу `TreeMap`:

import java.util.Map;  
import java.util.TreeMap;

public class TreeMapExample {  
public static void main(String\[\] args) {  
// Создаем TreeMap с естественным порядком (порядок ключей)  
Map\<Integer, String\> map \= new TreeMap\<\>();

        // Вставляем элементы  
        map.put(3, "Third");  
        map.put(1, "First");  
        map.put(2, "Second");

        // Элементы автоматически отсортированы по ключам  
        System.out.println("TreeMap in natural order:");  
        for (Map.Entry\<Integer, String\> entry : map.entrySet()) {  
            System.out.println(entry.getKey() \+ ": " \+ entry.getValue());  
        }

        // Доступ к первому и последнему ключу  
        System.out.println("First key: " \+ ((TreeMap\<Integer, String\>) map).firstKey());  
        System.out.println("Last key: " \+ ((TreeMap\<Integer, String\>) map).lastKey());  
    }  
}

### **Ожидаемый вывод:**

TreeMap in natural order:  
1: First  
2: Second  
3: Third  
First key: 1  
Last key: 3

### **Время выполнения операций в `TreeMap`**

| Операция | Средняя сложность | Худшая сложность |
| ----- | ----- | ----- |
| `put()` | **O(log n)** | **O(log n)** |
| `get()` | **O(log n)** | **O(log n)** |
| `remove()` | **O(log n)** | **O(log n)** |
| `firstKey()`, `lastKey()`, `higherKey()`, и т.д. | **O(log n)** | **O(log n)** |

### **Заключение**

`TreeMap` предоставляет отсортированную реализацию интерфейса `Map` с логарифмическим временем выполнения основных операций благодаря использованию красно-черного дерева. Это делает его отличным выбором для задач, требующих сохранения упорядоченности элементов и быстрой навигации по ним. Однако, по сравнению с `HashMap`, `TreeMap` имеет более высокие накладные расходы на операции, поэтому для задач, где не требуется упорядоченность, `HashMap` может быть более предпочтительным.

### `ListIterator`

`ListIterator` расширяет интерфейс `Iterator` и добавляет дополнительные возможности, особенно полезные при работе с двусвязными списками, такими как `LinkedList`.

#### Дополнительные методы `ListIterator`:

1. **`hasPrevious()`**
  - **Описание**: Проверяет, есть ли предыдущие элементы в списке перед текущей позицией.
  - **Возвращает**: `true`, если есть предыдущий элемент, иначе `false`.
  - **Пример**:
    ```java
    ListIterator<String> listIterator = list.listIterator();
    while (listIterator.hasNext()) {
        listIterator.next();
    }
    while (listIterator.hasPrevious()) {
        String element = listIterator.previous();
        // Обработка элемента
    }
    ```

2. **`previous()`**
  - **Описание**: Возвращает предыдущий элемент в списке и перемещает курсор итератора назад.
  - **Возвращает**: Предыдущий элемент.
  - **Исключения**: `NoSuchElementException`, если нет предыдущего элемента.
  - **Пример**:
    ```java
    String element = listIterator.previous();
    ```

3. **`add(E e)`**
  - **Описание**: Вставляет указанный элемент в текущую позицию итератора. Следующий вызов `next()` вернет только что добавленный элемент.
  - **Возвращает**: Ничего (void).
  - **Исключения**: `UnsupportedOperationException`, если операция не поддерживается.
  - **Пример**:
    ```java
    listIterator.add("newElement");
    ```

4. **`set(E e)`**
  - **Описание**: Заменяет последний возвращенный элемент с помощью `next()` или `previous()` на указанный элемент.
  - **Возвращает**: Ничего (void).
  - **Исключения**: `IllegalStateException`, если `next()` или `previous()` не были вызваны.
  - **Пример**:
    ```java
    listIterator.next();  // Возвращает элемент
    listIterator.set("updatedElement");  // Заменяет этот элемент
    ```

### Безопасность итераций

#### Проблема `ConcurrentModificationException`

- **Описание**: Исключение, которое возникает при изменении коллекции в процессе её итерации. Это происходит, если коллекция была изменена структурно (например, элемент был добавлен или удален) после создания итератора.
- **Пример**:
  ```java
  List<String> list = new ArrayList<>(Arrays.asList("a", "b", "c"));
  Iterator<String> iterator = list.iterator();
  while (iterator.hasNext()) {
      String element = iterator.next();
      list.remove(element);  // Генерирует ConcurrentModificationException
  }
  ```

#### Использование модифицируемых и немодифицируемых коллекций

- **Модифицируемые коллекции**: Это коллекции, которые позволяют вносить изменения в их содержимое (например, `ArrayList`, `HashSet`).
- **Немодифицируемые коллекции**: Это коллекции, которые не позволяют изменять их содержимое (например, через `Collections.unmodifiableList()`, `List.of()`).

- **Пример создания немодифицируемой коллекции**:
  ```java
  List<String> list = Arrays.asList("a", "b", "c");
  List<String> unmodifiableList = Collections.unmodifiableList(list);
  ```

#### Потокобезопасные итераторы

- **`CopyOnWriteArrayList`**: Коллекция, которая создает копию внутреннего массива при каждой модификации. Это позволяет безопасно итерировать по коллекции, даже если она изменяется в другой части программы.
  - **Пример**:
    ```java
    CopyOnWriteArrayList<String> list = new CopyOnWriteArrayList<>(Arrays.asList("a", "b", "c"));
    Iterator<String> iterator = list.iterator();
    list.add("d");  // Модификация коллекции
    while (iterator.hasNext()) {
        String element = iterator.next();  // Безопасно итерировать
    }
    ```

### Заключение

Итераторы и `ListIterator` предоставляют гибкость и возможности для работы с элементами коллекций в Java. Знание методов `Iterator` и `ListIterator`, а также умение работать с проблемами безопасности итераций, такими как `ConcurrentModificationException`, и использование потокобезопасных коллекций, являются важными навыками для Senior Java Developer. Эффективное использование итераторов и правильное управление изменениями коллекций помогут вам писать более надежный и эффективный код.

Для позиции Senior Java Developer важно хорошо разбираться в интерфейсах `Comparable` и `Comparator`, которые используются для сортировки и сравнения объектов в Java. Давайте рассмотрим их подробно, а также примеры их применения, включая использование лямбда-выражений и функциональных интерфейсов.

### Интерфейс `Comparable`

Интерфейс `Comparable` используется для определения естественного порядка объектов класса. Он содержит метод `compareTo()`, который должен быть реализован для сравнения текущего объекта с другим объектом того же типа.

#### Контракт метода `compareTo()`

- **Метод `compareTo(T o)`**:
  - **Описание**: Сравнивает текущий объект с объектом `o`. Возвращает целое число:
    - `0`, если объекты равны,
    - Отрицательное число, если текущий объект меньше `o`,
    - Положительное число, если текущий объект больше `o`.
  - **Пример**:
    ```java
    public class Person implements Comparable<Person> {
        private String name;
        private int age;

        public Person(String name, int age) {
            this.name = name;
            this.age = age;
        }

        @Override
        public int compareTo(Person other) {
            return Integer.compare(this.age, other.age);
        }

        // Геттеры и другие методы
    }
    ```

#### Примеры использования

1. **Сортировка через `Collections.sort()`**:
   ```java
   List<Person> people = Arrays.asList(
       new Person("Alice", 30),
       new Person("Bob", 25),
       new Person("Charlie", 35)
   );
   Collections.sort(people);
   // Список будет отсортирован по возрасту
   ```

2. **Использование в структурах данных**:
  - **`TreeSet`**:
    ```java
    Set<Person> personSet = new TreeSet<>();
    personSet.add(new Person("Alice", 30));
    personSet.add(new Person("Bob", 25));
    // Персон будет отсортирован по возрасту
    ```

  - **`TreeMap`**:
    ```java
    Map<Person, String> personMap = new TreeMap<>();
    personMap.put(new Person("Alice", 30), "Engineer");
    personMap.put(new Person("Bob", 25), "Doctor");
    // Ключи будут отсортированы по возрасту
    ```

### Интерфейс `Comparator`

Интерфейс `Comparator` предоставляет возможность внешней сортировки объектов. Это позволяет определять несколько разных критериев сортировки и применять их при необходимости.

#### Основные методы `Comparator`

1. **`compare(T o1, T o2)`**
  - **Описание**: Сравнивает два объекта `o1` и `o2`. Возвращает целое число:
    - `0`, если объекты равны,
    - Отрицательное число, если `o1` меньше `o2`,
    - Положительное число, если `o1` больше `o2`.
  - **Пример**:
    ```java
    public class PersonAgeComparator implements Comparator<Person> {
        @Override
        public int compare(Person p1, Person p2) {
            return Integer.compare(p1.getAge(), p2.getAge());
        }
    }
    ```

2. **Методы для создания цепочек компараторов**:
  - **`thenComparing(Comparator<? super T> other)`**: Создает компаратор, который сначала использует текущий компаратор, а затем, в случае равенства, использует указанный компаратор.
  - **Пример**:
    ```java
    Comparator<Person> byAge = Comparator.comparing(Person::getAge);
    Comparator<Person> byName = Comparator.comparing(Person::getName);
    Comparator<Person> byAgeThenName = byAge.thenComparing(byName);
    
    List<Person> people = Arrays.asList(
        new Person("Alice", 30),
        new Person("Bob", 25),
        new Person("Charlie", 25)
    );
    people.sort(byAgeThenName);
    // Список будет отсортирован по возрасту, затем по имени
    ```

### Отличие `Comparable` и `Comparator`

- **`Comparable`**:
  - Определяет естественный порядок объекта.
  - Реализуется в классе (например, `Person`).
  - Используется для однозначного и постоянного порядка.

- **`Comparator`**:
  - Позволяет определить несколько различных порядков для одного типа объекта.
  - Может быть реализован как отдельный класс или в виде лямбда-выражения.
  - Используется для различных вариантов сортировки.

### Лямбда-выражения и функциональные интерфейсы (Java 8+)

Начиная с Java 8, вы можете использовать лямбда-выражения для упрощения создания компараторов. Это особенно полезно для создания компараторов "на лету" и упрощения кода.

#### Примеры лямбда-выражений:

1. **Сортировка по одному критерию**:
   ```java
   List<Person> people = Arrays.asList(
       new Person("Alice", 30),
       new Person("Bob", 25),
       new Person("Charlie", 35)
   );
   people.sort((p1, p2) -> Integer.compare(p1.getAge(), p2.getAge()));
   ```

2. **Сортировка по нескольким критериям**:
   ```java
   people.sort(Comparator.comparing(Person::getAge)
                         .thenComparing(Person::getName));
   ```

### Примеры сортировок коллекций

1. **Сортировка по возрасту**:
   ```java
   List<Person> people = Arrays.asList(
       new Person("Alice", 30),
       new Person("Bob", 25),
       new Person("Charlie", 35)
   );
   people.sort(Comparator.comparing(Person::getAge));
   ```

2. **Сортировка по имени в обратном порядке**:
   ```java
   people.sort(Comparator.comparing(Person::getName).reversed());
   ```

3. **Сортировка по возрасту, затем по имени**:
   ```java
   people.sort(Comparator.comparing(Person::getAge)
                        .thenComparing(Person::getName));
   ```

4. **Сортировка с использованием лямбда-выражений**:
   ```java
   people.sort((p1, p2) -> {
       int ageCompare = Integer.compare(p1.getAge(), p2.getAge());
       if (ageCompare != 0) return ageCompare;
       return p1.getName().compareTo(p2.getName());
   });
   ```

### Заключение

Интерфейсы `Comparable` и `Comparator` предоставляют мощные средства для сортировки объектов в Java. Понимание их работы и правильное использование этих интерфейсов помогут вам создавать гибкие и эффективные решения для сортировки и сравнения данных. Использование лямбда-выражений и функциональных интерфейсов с Java 8 и выше делает код более читаемым и поддерживаемым.

## Вопросы на собеседовании

